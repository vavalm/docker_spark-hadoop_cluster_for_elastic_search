Spark Executor Command: "/usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java" "-cp" "/root/spark/conf/:/root/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=39269" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@master:39269" "--executor-id" "1" "--hostname" "172.23.0.3" "--cores" "1" "--app-id" "app-20191202094817-0000" "--worker-url" "spark://Worker@172.23.0.3:44441"
========================================

Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
19/12/02 17:48:18 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 275@slave1
19/12/02 17:48:18 INFO SignalUtils: Registered signal handler for TERM
19/12/02 17:48:18 INFO SignalUtils: Registered signal handler for HUP
19/12/02 17:48:18 INFO SignalUtils: Registered signal handler for INT
19/12/02 17:48:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/12/02 17:48:19 INFO SecurityManager: Changing view acls to: root
19/12/02 17:48:19 INFO SecurityManager: Changing modify acls to: root
19/12/02 17:48:19 INFO SecurityManager: Changing view acls groups to: 
19/12/02 17:48:19 INFO SecurityManager: Changing modify acls groups to: 
19/12/02 17:48:19 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/12/02 17:48:20 INFO TransportClientFactory: Successfully created connection to master/172.23.0.2:39269 after 128 ms (0 ms spent in bootstraps)
19/12/02 17:48:20 INFO SecurityManager: Changing view acls to: root
19/12/02 17:48:20 INFO SecurityManager: Changing modify acls to: root
19/12/02 17:48:20 INFO SecurityManager: Changing view acls groups to: 
19/12/02 17:48:20 INFO SecurityManager: Changing modify acls groups to: 
19/12/02 17:48:20 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/12/02 17:48:20 INFO TransportClientFactory: Successfully created connection to master/172.23.0.2:39269 after 22 ms (0 ms spent in bootstraps)
19/12/02 17:48:20 INFO DiskBlockManager: Created local directory at /tmp/spark-a1042d3d-2517-445b-90cb-390ce5e97129/executor-102d8988-bfa9-430e-9330-8efcd28d7546/blockmgr-310b1357-2b78-4499-a80d-4d6b1d272cfa
19/12/02 17:48:20 INFO MemoryStore: MemoryStore started with capacity 413.9 MB
19/12/02 17:48:20 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@master:39269
19/12/02 17:48:20 INFO WorkerWatcher: Connecting to worker spark://Worker@172.23.0.3:44441
19/12/02 17:48:20 INFO WorkerWatcher: Successfully connected to spark://Worker@172.23.0.3:44441
19/12/02 17:48:20 INFO TransportClientFactory: Successfully created connection to /172.23.0.3:44441 after 5 ms (0 ms spent in bootstraps)
19/12/02 17:48:21 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
19/12/02 17:48:21 INFO Executor: Starting executor ID 1 on host 172.23.0.3
19/12/02 17:48:21 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44147.
19/12/02 17:48:21 INFO NettyBlockTransferService: Server created on 172.23.0.3:44147
19/12/02 17:48:21 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/12/02 17:48:21 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(1, 172.23.0.3, 44147, None)
19/12/02 17:48:21 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(1, 172.23.0.3, 44147, None)
19/12/02 17:48:21 INFO BlockManager: Initialized BlockManager: BlockManagerId(1, 172.23.0.3, 44147, None)
19/12/02 17:48:21 INFO CoarseGrainedExecutorBackend: Got assigned task 1
19/12/02 17:48:21 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
19/12/02 17:48:21 INFO TorrentBroadcast: Started reading broadcast variable 1
19/12/02 17:48:21 INFO TransportClientFactory: Successfully created connection to master/172.23.0.2:44967 after 2 ms (0 ms spent in bootstraps)
19/12/02 17:48:21 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.2 KB, free 413.9 MB)
19/12/02 17:48:21 INFO TorrentBroadcast: Reading broadcast variable 1 took 114 ms
19/12/02 17:48:21 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.1 KB, free 413.9 MB)
19/12/02 17:48:21 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:16777216+16777216
19/12/02 17:48:21 INFO TorrentBroadcast: Started reading broadcast variable 0
19/12/02 17:48:21 INFO TransportClientFactory: Successfully created connection to /172.23.0.4:34227 after 0 ms (0 ms spent in bootstraps)
19/12/02 17:48:21 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.9 KB, free 413.9 MB)
19/12/02 17:48:21 INFO TorrentBroadcast: Reading broadcast variable 0 took 54 ms
19/12/02 17:48:22 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 320.9 KB, free 413.6 MB)
19/12/02 17:48:32 INFO PythonRunner: Times: total = 9031, boot = 715, init = 64, finish = 8252
19/12/02 17:48:32 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1785 bytes result sent to driver
19/12/02 17:48:32 INFO CoarseGrainedExecutorBackend: Got assigned task 2
19/12/02 17:48:32 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
19/12/02 17:48:32 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:33554432+16777216
19/12/02 17:48:41 INFO PythonRunner: Times: total = 8448, boot = -699, init = 728, finish = 8419
19/12/02 17:48:41 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1742 bytes result sent to driver
19/12/02 17:48:41 INFO CoarseGrainedExecutorBackend: Got assigned task 5
19/12/02 17:48:41 INFO Executor: Running task 5.0 in stage 0.0 (TID 5)
19/12/02 17:48:41 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:83886080+16777216
19/12/02 17:48:49 INFO PythonRunner: Times: total = 8288, boot = -157, init = 183, finish = 8262
19/12/02 17:48:49 INFO Executor: Finished task 5.0 in stage 0.0 (TID 5). 1742 bytes result sent to driver
19/12/02 17:48:49 INFO CoarseGrainedExecutorBackend: Got assigned task 7
19/12/02 17:48:49 INFO Executor: Running task 7.0 in stage 0.0 (TID 7)
19/12/02 17:48:49 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:117440512+16777216
19/12/02 17:48:59 INFO PythonRunner: Times: total = 8915, boot = -154, init = 166, finish = 8903
19/12/02 17:48:59 INFO Executor: Finished task 7.0 in stage 0.0 (TID 7). 1742 bytes result sent to driver
19/12/02 17:48:59 INFO CoarseGrainedExecutorBackend: Got assigned task 9
19/12/02 17:48:59 INFO Executor: Running task 9.0 in stage 0.0 (TID 9)
19/12/02 17:48:59 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:150994944+16777216
19/12/02 17:49:07 INFO PythonRunner: Times: total = 8560, boot = -142, init = 167, finish = 8535
19/12/02 17:49:07 INFO Executor: Finished task 9.0 in stage 0.0 (TID 9). 1742 bytes result sent to driver
19/12/02 17:49:07 INFO CoarseGrainedExecutorBackend: Got assigned task 11
19/12/02 17:49:07 INFO Executor: Running task 11.0 in stage 0.0 (TID 11)
19/12/02 17:49:07 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:184549376+16777216
19/12/02 17:49:16 INFO PythonRunner: Times: total = 8495, boot = -82, init = 92, finish = 8485
19/12/02 17:49:16 INFO Executor: Finished task 11.0 in stage 0.0 (TID 11). 1785 bytes result sent to driver
19/12/02 17:49:16 INFO CoarseGrainedExecutorBackend: Got assigned task 13
19/12/02 17:49:16 INFO Executor: Running task 13.0 in stage 0.0 (TID 13)
19/12/02 17:49:16 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:218103808+16777216
19/12/02 17:49:25 INFO PythonRunner: Times: total = 8718, boot = -143, init = 154, finish = 8707
19/12/02 17:49:25 INFO Executor: Finished task 13.0 in stage 0.0 (TID 13). 1742 bytes result sent to driver
19/12/02 17:49:25 INFO CoarseGrainedExecutorBackend: Got assigned task 15
19/12/02 17:49:25 INFO Executor: Running task 15.0 in stage 0.0 (TID 15)
19/12/02 17:49:25 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:251658240+16777216
19/12/02 17:49:34 INFO PythonRunner: Times: total = 8719, boot = -96, init = 119, finish = 8696
19/12/02 17:49:34 INFO Executor: Finished task 15.0 in stage 0.0 (TID 15). 1742 bytes result sent to driver
19/12/02 17:49:34 INFO CoarseGrainedExecutorBackend: Got assigned task 17
19/12/02 17:49:34 INFO Executor: Running task 17.0 in stage 0.0 (TID 17)
19/12/02 17:49:34 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:285212672+16777216
19/12/02 17:49:42 INFO PythonRunner: Times: total = 8449, boot = -64, init = 87, finish = 8426
19/12/02 17:49:42 INFO Executor: Finished task 17.0 in stage 0.0 (TID 17). 1742 bytes result sent to driver
19/12/02 17:49:42 INFO CoarseGrainedExecutorBackend: Got assigned task 19
19/12/02 17:49:42 INFO Executor: Running task 19.0 in stage 0.0 (TID 19)
19/12/02 17:49:42 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:318767104+16777216
19/12/02 17:49:51 INFO PythonRunner: Times: total = 8471, boot = -67, init = 92, finish = 8446
19/12/02 17:49:51 INFO Executor: Finished task 19.0 in stage 0.0 (TID 19). 1742 bytes result sent to driver
19/12/02 17:49:51 INFO CoarseGrainedExecutorBackend: Got assigned task 21
19/12/02 17:49:51 INFO Executor: Running task 21.0 in stage 0.0 (TID 21)
19/12/02 17:49:51 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:352321536+16777216
19/12/02 17:49:59 INFO PythonRunner: Times: total = 8515, boot = -74, init = 86, finish = 8503
19/12/02 17:49:59 INFO Executor: Finished task 21.0 in stage 0.0 (TID 21). 1742 bytes result sent to driver
19/12/02 17:49:59 INFO CoarseGrainedExecutorBackend: Got assigned task 23
19/12/02 17:49:59 INFO Executor: Running task 23.0 in stage 0.0 (TID 23)
19/12/02 17:49:59 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:385875968+16777216
19/12/02 17:50:08 INFO PythonRunner: Times: total = 8633, boot = -50, init = 65, finish = 8618
19/12/02 17:50:08 INFO Executor: Finished task 23.0 in stage 0.0 (TID 23). 1742 bytes result sent to driver
19/12/02 17:50:08 INFO CoarseGrainedExecutorBackend: Got assigned task 25
19/12/02 17:50:08 INFO Executor: Running task 25.0 in stage 0.0 (TID 25)
19/12/02 17:50:08 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:419430400+16777216
19/12/02 17:50:17 INFO PythonRunner: Times: total = 8455, boot = -60, init = 71, finish = 8444
19/12/02 17:50:17 INFO Executor: Finished task 25.0 in stage 0.0 (TID 25). 1742 bytes result sent to driver
19/12/02 17:50:17 INFO CoarseGrainedExecutorBackend: Got assigned task 27
19/12/02 17:50:17 INFO Executor: Running task 27.0 in stage 0.0 (TID 27)
19/12/02 17:50:17 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:452984832+16777216
19/12/02 17:50:25 INFO PythonRunner: Times: total = 8413, boot = -87, init = 98, finish = 8402
19/12/02 17:50:25 INFO Executor: Finished task 27.0 in stage 0.0 (TID 27). 1742 bytes result sent to driver
19/12/02 17:50:25 INFO CoarseGrainedExecutorBackend: Got assigned task 29
19/12/02 17:50:25 INFO Executor: Running task 29.0 in stage 0.0 (TID 29)
19/12/02 17:50:25 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:486539264+16777216
19/12/02 17:50:34 INFO PythonRunner: Times: total = 8505, boot = -34, init = 46, finish = 8493
19/12/02 17:50:34 INFO Executor: Finished task 29.0 in stage 0.0 (TID 29). 1742 bytes result sent to driver
19/12/02 17:50:34 INFO CoarseGrainedExecutorBackend: Got assigned task 31
19/12/02 17:50:34 INFO Executor: Running task 31.0 in stage 0.0 (TID 31)
19/12/02 17:50:34 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:520093696+16777216
19/12/02 17:50:42 INFO PythonRunner: Times: total = 8278, boot = -70, init = 81, finish = 8267
19/12/02 17:50:42 INFO Executor: Finished task 31.0 in stage 0.0 (TID 31). 1742 bytes result sent to driver
19/12/02 17:50:42 INFO CoarseGrainedExecutorBackend: Got assigned task 33
19/12/02 17:50:42 INFO Executor: Running task 1.0 in stage 1.0 (TID 33)
19/12/02 17:50:42 INFO MapOutputTrackerWorker: Updating epoch to 1 and clearing cache
19/12/02 17:50:42 INFO TorrentBroadcast: Started reading broadcast variable 2
19/12/02 17:50:42 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 29.6 KB, free 413.5 MB)
19/12/02 17:50:42 INFO TorrentBroadcast: Reading broadcast variable 2 took 14 ms
19/12/02 17:50:42 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 77.3 KB, free 413.5 MB)
19/12/02 17:50:42 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
19/12/02 17:50:42 INFO MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@master:39269)
19/12/02 17:50:42 INFO MapOutputTrackerWorker: Got the output locations
19/12/02 17:50:42 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/12/02 17:50:42 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 63 ms
19/12/02 17:50:42 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/12/02 17:50:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/12/02 17:50:43 INFO PythonRunner: Times: total = 85, boot = -296, init = 380, finish = 1
19/12/02 17:50:43 INFO FileOutputCommitter: Saved output of task 'attempt_20191202094820_0008_m_000001_0' to hdfs://master:54310/output/_temporary/0/task_20191202094820_0008_m_000001
19/12/02 17:50:43 INFO SparkHadoopMapRedUtil: attempt_20191202094820_0008_m_000001_0: Committed
19/12/02 17:50:43 INFO Executor: Finished task 1.0 in stage 1.0 (TID 33). 2110 bytes result sent to driver
19/12/02 17:50:43 INFO CoarseGrainedExecutorBackend: Got assigned task 35
19/12/02 17:50:43 INFO Executor: Running task 3.0 in stage 1.0 (TID 35)
19/12/02 17:50:43 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/12/02 17:50:43 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 3 ms
19/12/02 17:50:43 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/12/02 17:50:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/12/02 17:50:43 INFO PythonRunner: Times: total = 65, boot = -310, init = 374, finish = 1
19/12/02 17:50:43 INFO FileOutputCommitter: Saved output of task 'attempt_20191202094820_0008_m_000003_0' to hdfs://master:54310/output/_temporary/0/task_20191202094820_0008_m_000003
19/12/02 17:50:43 INFO SparkHadoopMapRedUtil: attempt_20191202094820_0008_m_000003_0: Committed
19/12/02 17:50:43 INFO Executor: Finished task 3.0 in stage 1.0 (TID 35). 2024 bytes result sent to driver
19/12/02 17:50:43 INFO CoarseGrainedExecutorBackend: Got assigned task 37
19/12/02 17:50:43 INFO Executor: Running task 5.0 in stage 1.0 (TID 37)
19/12/02 17:50:43 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/12/02 17:50:43 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 8 ms
19/12/02 17:50:43 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/12/02 17:50:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/12/02 17:50:43 INFO PythonRunner: Times: total = 74, boot = -107, init = 181, finish = 0
19/12/02 17:50:43 INFO FileOutputCommitter: Saved output of task 'attempt_20191202094820_0008_m_000005_0' to hdfs://master:54310/output/_temporary/0/task_20191202094820_0008_m_000005
19/12/02 17:50:43 INFO SparkHadoopMapRedUtil: attempt_20191202094820_0008_m_000005_0: Committed
19/12/02 17:50:43 INFO Executor: Finished task 5.0 in stage 1.0 (TID 37). 2024 bytes result sent to driver
19/12/02 17:50:43 INFO CoarseGrainedExecutorBackend: Got assigned task 39
19/12/02 17:50:43 INFO Executor: Running task 7.0 in stage 1.0 (TID 39)
19/12/02 17:50:43 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/12/02 17:50:43 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 2 ms
19/12/02 17:50:43 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/12/02 17:50:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/12/02 17:50:43 INFO PythonRunner: Times: total = 85, boot = -97, init = 182, finish = 0
19/12/02 17:50:43 INFO FileOutputCommitter: Saved output of task 'attempt_20191202094820_0008_m_000007_0' to hdfs://master:54310/output/_temporary/0/task_20191202094820_0008_m_000007
19/12/02 17:50:43 INFO SparkHadoopMapRedUtil: attempt_20191202094820_0008_m_000007_0: Committed
19/12/02 17:50:43 INFO Executor: Finished task 7.0 in stage 1.0 (TID 39). 2024 bytes result sent to driver
19/12/02 17:50:43 INFO CoarseGrainedExecutorBackend: Got assigned task 41
19/12/02 17:50:43 INFO Executor: Running task 9.0 in stage 1.0 (TID 41)
19/12/02 17:50:43 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/12/02 17:50:43 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 10 ms
19/12/02 17:50:43 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/12/02 17:50:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/12/02 17:50:43 INFO PythonRunner: Times: total = 72, boot = -97, init = 169, finish = 0
19/12/02 17:50:44 INFO FileOutputCommitter: Saved output of task 'attempt_20191202094820_0008_m_000009_0' to hdfs://master:54310/output/_temporary/0/task_20191202094820_0008_m_000009
19/12/02 17:50:44 INFO SparkHadoopMapRedUtil: attempt_20191202094820_0008_m_000009_0: Committed
19/12/02 17:50:44 INFO Executor: Finished task 9.0 in stage 1.0 (TID 41). 2024 bytes result sent to driver
19/12/02 17:50:44 INFO CoarseGrainedExecutorBackend: Got assigned task 43
19/12/02 17:50:44 INFO Executor: Running task 11.0 in stage 1.0 (TID 43)
19/12/02 17:50:44 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/12/02 17:50:44 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 7 ms
19/12/02 17:50:44 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/12/02 17:50:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/12/02 17:50:44 INFO PythonRunner: Times: total = 92, boot = -119, init = 211, finish = 0
19/12/02 17:50:44 INFO FileOutputCommitter: Saved output of task 'attempt_20191202094820_0008_m_000011_0' to hdfs://master:54310/output/_temporary/0/task_20191202094820_0008_m_000011
19/12/02 17:50:44 INFO SparkHadoopMapRedUtil: attempt_20191202094820_0008_m_000011_0: Committed
19/12/02 17:50:44 INFO Executor: Finished task 11.0 in stage 1.0 (TID 43). 2024 bytes result sent to driver
19/12/02 17:50:44 INFO CoarseGrainedExecutorBackend: Got assigned task 45
19/12/02 17:50:44 INFO Executor: Running task 13.0 in stage 1.0 (TID 45)
19/12/02 17:50:44 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/12/02 17:50:44 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 14 ms
19/12/02 17:50:44 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/12/02 17:50:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/12/02 17:50:44 INFO PythonRunner: Times: total = 81, boot = -125, init = 205, finish = 1
19/12/02 17:50:44 INFO FileOutputCommitter: Saved output of task 'attempt_20191202094820_0008_m_000013_0' to hdfs://master:54310/output/_temporary/0/task_20191202094820_0008_m_000013
19/12/02 17:50:44 INFO SparkHadoopMapRedUtil: attempt_20191202094820_0008_m_000013_0: Committed
19/12/02 17:50:44 INFO Executor: Finished task 13.0 in stage 1.0 (TID 45). 2024 bytes result sent to driver
19/12/02 17:50:44 INFO CoarseGrainedExecutorBackend: Got assigned task 47
19/12/02 17:50:44 INFO Executor: Running task 15.0 in stage 1.0 (TID 47)
19/12/02 17:50:44 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/12/02 17:50:44 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 9 ms
19/12/02 17:50:44 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/12/02 17:50:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/12/02 17:50:44 INFO PythonRunner: Times: total = 70, boot = -123, init = 193, finish = 0
19/12/02 17:50:44 INFO FileOutputCommitter: Saved output of task 'attempt_20191202094820_0008_m_000015_0' to hdfs://master:54310/output/_temporary/0/task_20191202094820_0008_m_000015
19/12/02 17:50:44 INFO SparkHadoopMapRedUtil: attempt_20191202094820_0008_m_000015_0: Committed
19/12/02 17:50:44 INFO Executor: Finished task 15.0 in stage 1.0 (TID 47). 2067 bytes result sent to driver
19/12/02 17:50:44 INFO CoarseGrainedExecutorBackend: Got assigned task 49
19/12/02 17:50:44 INFO Executor: Running task 17.0 in stage 1.0 (TID 49)
19/12/02 17:50:44 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/12/02 17:50:44 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 13 ms
19/12/02 17:50:44 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/12/02 17:50:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/12/02 17:50:44 INFO PythonRunner: Times: total = 59, boot = -95, init = 153, finish = 1
19/12/02 17:50:44 INFO FileOutputCommitter: Saved output of task 'attempt_20191202094820_0008_m_000017_0' to hdfs://master:54310/output/_temporary/0/task_20191202094820_0008_m_000017
19/12/02 17:50:44 INFO SparkHadoopMapRedUtil: attempt_20191202094820_0008_m_000017_0: Committed
19/12/02 17:50:44 INFO Executor: Finished task 17.0 in stage 1.0 (TID 49). 2024 bytes result sent to driver
19/12/02 17:50:44 INFO CoarseGrainedExecutorBackend: Got assigned task 51
19/12/02 17:50:44 INFO Executor: Running task 19.0 in stage 1.0 (TID 51)
19/12/02 17:50:44 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/12/02 17:50:44 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 20 ms
19/12/02 17:50:44 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/12/02 17:50:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/12/02 17:50:44 INFO PythonRunner: Times: total = 69, boot = -107, init = 175, finish = 1
19/12/02 17:50:44 INFO FileOutputCommitter: Saved output of task 'attempt_20191202094820_0008_m_000019_0' to hdfs://master:54310/output/_temporary/0/task_20191202094820_0008_m_000019
19/12/02 17:50:44 INFO SparkHadoopMapRedUtil: attempt_20191202094820_0008_m_000019_0: Committed
19/12/02 17:50:44 INFO Executor: Finished task 19.0 in stage 1.0 (TID 51). 2067 bytes result sent to driver
19/12/02 17:50:44 INFO CoarseGrainedExecutorBackend: Got assigned task 53
19/12/02 17:50:44 INFO Executor: Running task 21.0 in stage 1.0 (TID 53)
19/12/02 17:50:44 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/12/02 17:50:44 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 11 ms
19/12/02 17:50:44 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/12/02 17:50:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/12/02 17:50:45 INFO PythonRunner: Times: total = 62, boot = -93, init = 155, finish = 0
19/12/02 17:50:45 INFO FileOutputCommitter: Saved output of task 'attempt_20191202094820_0008_m_000021_0' to hdfs://master:54310/output/_temporary/0/task_20191202094820_0008_m_000021
19/12/02 17:50:45 INFO SparkHadoopMapRedUtil: attempt_20191202094820_0008_m_000021_0: Committed
19/12/02 17:50:45 INFO Executor: Finished task 21.0 in stage 1.0 (TID 53). 2024 bytes result sent to driver
19/12/02 17:50:45 INFO CoarseGrainedExecutorBackend: Got assigned task 55
19/12/02 17:50:45 INFO Executor: Running task 23.0 in stage 1.0 (TID 55)
19/12/02 17:50:45 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/12/02 17:50:45 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 8 ms
19/12/02 17:50:45 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/12/02 17:50:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/12/02 17:50:45 INFO PythonRunner: Times: total = 81, boot = -108, init = 189, finish = 0
19/12/02 17:50:45 INFO FileOutputCommitter: Saved output of task 'attempt_20191202094820_0008_m_000023_0' to hdfs://master:54310/output/_temporary/0/task_20191202094820_0008_m_000023
19/12/02 17:50:45 INFO SparkHadoopMapRedUtil: attempt_20191202094820_0008_m_000023_0: Committed
19/12/02 17:50:45 INFO Executor: Finished task 23.0 in stage 1.0 (TID 55). 2024 bytes result sent to driver
19/12/02 17:50:45 INFO CoarseGrainedExecutorBackend: Got assigned task 57
19/12/02 17:50:45 INFO Executor: Running task 25.0 in stage 1.0 (TID 57)
19/12/02 17:50:45 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/12/02 17:50:45 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 5 ms
19/12/02 17:50:45 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/12/02 17:50:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/12/02 17:50:45 INFO PythonRunner: Times: total = 65, boot = -83, init = 148, finish = 0
19/12/02 17:50:45 INFO FileOutputCommitter: Saved output of task 'attempt_20191202094820_0008_m_000025_0' to hdfs://master:54310/output/_temporary/0/task_20191202094820_0008_m_000025
19/12/02 17:50:45 INFO SparkHadoopMapRedUtil: attempt_20191202094820_0008_m_000025_0: Committed
19/12/02 17:50:45 INFO Executor: Finished task 25.0 in stage 1.0 (TID 57). 2024 bytes result sent to driver
19/12/02 17:50:45 INFO CoarseGrainedExecutorBackend: Got assigned task 59
19/12/02 17:50:45 INFO Executor: Running task 27.0 in stage 1.0 (TID 59)
19/12/02 17:50:45 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/12/02 17:50:45 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 3 ms
19/12/02 17:50:45 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/12/02 17:50:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/12/02 17:50:45 INFO PythonRunner: Times: total = 76, boot = -107, init = 183, finish = 0
19/12/02 17:50:45 INFO FileOutputCommitter: Saved output of task 'attempt_20191202094820_0008_m_000027_0' to hdfs://master:54310/output/_temporary/0/task_20191202094820_0008_m_000027
19/12/02 17:50:45 INFO SparkHadoopMapRedUtil: attempt_20191202094820_0008_m_000027_0: Committed
19/12/02 17:50:45 INFO Executor: Finished task 27.0 in stage 1.0 (TID 59). 2024 bytes result sent to driver
19/12/02 17:50:45 INFO CoarseGrainedExecutorBackend: Got assigned task 61
19/12/02 17:50:45 INFO Executor: Running task 30.0 in stage 1.0 (TID 61)
19/12/02 17:50:45 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/12/02 17:50:45 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 1 ms
19/12/02 17:50:45 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/12/02 17:50:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/12/02 17:50:45 INFO PythonRunner: Times: total = 67, boot = -87, init = 154, finish = 0
19/12/02 17:50:45 INFO FileOutputCommitter: Saved output of task 'attempt_20191202094820_0008_m_000030_0' to hdfs://master:54310/output/_temporary/0/task_20191202094820_0008_m_000030
19/12/02 17:50:45 INFO SparkHadoopMapRedUtil: attempt_20191202094820_0008_m_000030_0: Committed
19/12/02 17:50:45 INFO Executor: Finished task 30.0 in stage 1.0 (TID 61). 2024 bytes result sent to driver
19/12/02 17:50:45 INFO CoarseGrainedExecutorBackend: Got assigned task 63
19/12/02 17:50:45 INFO Executor: Running task 28.0 in stage 1.0 (TID 63)
19/12/02 17:50:45 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
19/12/02 17:50:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
19/12/02 17:50:45 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/12/02 17:50:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/12/02 17:50:45 INFO PythonRunner: Times: total = 58, boot = -111, init = 169, finish = 0
19/12/02 17:50:45 INFO FileOutputCommitter: Saved output of task 'attempt_20191202094820_0008_m_000028_0' to hdfs://master:54310/output/_temporary/0/task_20191202094820_0008_m_000028
19/12/02 17:50:45 INFO SparkHadoopMapRedUtil: attempt_20191202094820_0008_m_000028_0: Committed
19/12/02 17:50:45 INFO Executor: Finished task 28.0 in stage 1.0 (TID 63). 1981 bytes result sent to driver
19/12/02 17:50:46 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
19/12/02 17:50:46 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
tdown
