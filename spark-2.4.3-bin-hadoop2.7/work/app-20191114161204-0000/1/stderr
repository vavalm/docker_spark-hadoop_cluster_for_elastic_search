Spark Executor Command: "/usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java" "-cp" "/root/spark/conf/:/root/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=39285" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@master:39285" "--executor-id" "1" "--hostname" "172.23.0.4" "--cores" "1" "--app-id" "app-20191114161204-0000" "--worker-url" "spark://Worker@172.23.0.4:43861"
========================================

Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
19/11/15 00:12:05 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 240@slave2
19/11/15 00:12:05 INFO SignalUtils: Registered signal handler for TERM
19/11/15 00:12:05 INFO SignalUtils: Registered signal handler for HUP
19/11/15 00:12:05 INFO SignalUtils: Registered signal handler for INT
19/11/15 00:12:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/11/15 00:12:06 INFO SecurityManager: Changing view acls to: root
19/11/15 00:12:06 INFO SecurityManager: Changing modify acls to: root
19/11/15 00:12:06 INFO SecurityManager: Changing view acls groups to: 
19/11/15 00:12:06 INFO SecurityManager: Changing modify acls groups to: 
19/11/15 00:12:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/11/15 00:12:07 INFO TransportClientFactory: Successfully created connection to master/172.23.0.2:39285 after 120 ms (0 ms spent in bootstraps)
19/11/15 00:12:07 INFO SecurityManager: Changing view acls to: root
19/11/15 00:12:07 INFO SecurityManager: Changing modify acls to: root
19/11/15 00:12:07 INFO SecurityManager: Changing view acls groups to: 
19/11/15 00:12:07 INFO SecurityManager: Changing modify acls groups to: 
19/11/15 00:12:07 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/11/15 00:12:07 INFO TransportClientFactory: Successfully created connection to master/172.23.0.2:39285 after 12 ms (0 ms spent in bootstraps)
19/11/15 00:12:07 INFO DiskBlockManager: Created local directory at /tmp/spark-769175e0-2c93-42c2-8c6b-fae97c7ba45b/executor-b4226811-83b6-4372-b1f7-b62d6fa407c4/blockmgr-7188211f-827d-4090-86ac-2f7a948a3881
19/11/15 00:12:07 INFO MemoryStore: MemoryStore started with capacity 413.9 MB
19/11/15 00:12:07 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@master:39285
19/11/15 00:12:07 INFO WorkerWatcher: Connecting to worker spark://Worker@172.23.0.4:43861
19/11/15 00:12:07 INFO TransportClientFactory: Successfully created connection to /172.23.0.4:43861 after 6 ms (0 ms spent in bootstraps)
19/11/15 00:12:07 INFO WorkerWatcher: Successfully connected to spark://Worker@172.23.0.4:43861
19/11/15 00:12:07 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
19/11/15 00:12:07 INFO Executor: Starting executor ID 1 on host 172.23.0.4
19/11/15 00:12:08 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38815.
19/11/15 00:12:08 INFO NettyBlockTransferService: Server created on 172.23.0.4:38815
19/11/15 00:12:08 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/11/15 00:12:08 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(1, 172.23.0.4, 38815, None)
19/11/15 00:12:08 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(1, 172.23.0.4, 38815, None)
19/11/15 00:12:08 INFO BlockManager: Initialized BlockManager: BlockManagerId(1, 172.23.0.4, 38815, None)
19/11/15 00:12:08 INFO CoarseGrainedExecutorBackend: Got assigned task 1
19/11/15 00:12:08 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
19/11/15 00:12:08 INFO TorrentBroadcast: Started reading broadcast variable 1
19/11/15 00:12:08 INFO TransportClientFactory: Successfully created connection to master/172.23.0.2:45185 after 2 ms (0 ms spent in bootstraps)
19/11/15 00:12:08 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.2 KB, free 413.9 MB)
19/11/15 00:12:08 INFO TorrentBroadcast: Reading broadcast variable 1 took 150 ms
19/11/15 00:12:08 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.1 KB, free 413.9 MB)
19/11/15 00:12:08 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:16777216+16777216
19/11/15 00:12:08 INFO TorrentBroadcast: Started reading broadcast variable 0
19/11/15 00:12:08 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.9 KB, free 413.9 MB)
19/11/15 00:12:08 INFO TorrentBroadcast: Reading broadcast variable 0 took 16 ms
19/11/15 00:12:08 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 320.9 KB, free 413.6 MB)
19/11/15 00:12:19 INFO PythonRunner: Times: total = 9117, boot = 867, init = 72, finish = 8178
19/11/15 00:12:19 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1742 bytes result sent to driver
19/11/15 00:12:19 INFO CoarseGrainedExecutorBackend: Got assigned task 2
19/11/15 00:12:19 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
19/11/15 00:12:19 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:33554432+16777216
19/11/15 00:12:27 INFO PythonRunner: Times: total = 7887, boot = -760, init = 777, finish = 7870
19/11/15 00:12:28 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1742 bytes result sent to driver
19/11/15 00:12:28 INFO CoarseGrainedExecutorBackend: Got assigned task 4
19/11/15 00:12:28 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
19/11/15 00:12:28 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:67108864+16777216
19/11/15 00:12:35 INFO PythonRunner: Times: total = 7781, boot = -166, init = 177, finish = 7770
19/11/15 00:12:35 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1742 bytes result sent to driver
19/11/15 00:12:35 INFO CoarseGrainedExecutorBackend: Got assigned task 6
19/11/15 00:12:35 INFO Executor: Running task 6.0 in stage 0.0 (TID 6)
19/11/15 00:12:35 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:100663296+16777216
19/11/15 00:12:45 INFO PythonRunner: Times: total = 8897, boot = -128, init = 141, finish = 8884
19/11/15 00:12:45 INFO Executor: Finished task 6.0 in stage 0.0 (TID 6). 1785 bytes result sent to driver
19/11/15 00:12:45 INFO CoarseGrainedExecutorBackend: Got assigned task 9
19/11/15 00:12:45 INFO Executor: Running task 9.0 in stage 0.0 (TID 9)
19/11/15 00:12:45 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:150994944+16777216
19/11/15 00:12:54 INFO PythonRunner: Times: total = 8849, boot = -172, init = 197, finish = 8824
19/11/15 00:12:54 INFO Executor: Finished task 9.0 in stage 0.0 (TID 9). 1742 bytes result sent to driver
19/11/15 00:12:54 INFO CoarseGrainedExecutorBackend: Got assigned task 11
19/11/15 00:12:54 INFO Executor: Running task 11.0 in stage 0.0 (TID 11)
19/11/15 00:12:54 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:184549376+16777216
19/11/15 00:13:03 INFO PythonRunner: Times: total = 9154, boot = -136, init = 160, finish = 9130
19/11/15 00:13:03 INFO Executor: Finished task 11.0 in stage 0.0 (TID 11). 1785 bytes result sent to driver
19/11/15 00:13:03 INFO CoarseGrainedExecutorBackend: Got assigned task 13
19/11/15 00:13:03 INFO Executor: Running task 13.0 in stage 0.0 (TID 13)
19/11/15 00:13:03 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:218103808+16777216
19/11/15 00:13:12 INFO PythonRunner: Times: total = 8711, boot = -144, init = 168, finish = 8687
19/11/15 00:13:12 INFO Executor: Finished task 13.0 in stage 0.0 (TID 13). 1699 bytes result sent to driver
19/11/15 00:13:12 INFO CoarseGrainedExecutorBackend: Got assigned task 15
19/11/15 00:13:12 INFO Executor: Running task 15.0 in stage 0.0 (TID 15)
19/11/15 00:13:12 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:251658240+16777216
19/11/15 00:13:20 INFO PythonRunner: Times: total = 8446, boot = -115, init = 132, finish = 8429
19/11/15 00:13:20 INFO Executor: Finished task 15.0 in stage 0.0 (TID 15). 1742 bytes result sent to driver
19/11/15 00:13:20 INFO CoarseGrainedExecutorBackend: Got assigned task 17
19/11/15 00:13:20 INFO Executor: Running task 17.0 in stage 0.0 (TID 17)
19/11/15 00:13:20 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:285212672+16777216
19/11/15 00:13:29 INFO PythonRunner: Times: total = 8303, boot = -92, init = 126, finish = 8269
19/11/15 00:13:29 INFO Executor: Finished task 17.0 in stage 0.0 (TID 17). 1742 bytes result sent to driver
19/11/15 00:13:29 INFO CoarseGrainedExecutorBackend: Got assigned task 19
19/11/15 00:13:29 INFO Executor: Running task 19.0 in stage 0.0 (TID 19)
19/11/15 00:13:29 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:318767104+16777216
19/11/15 00:13:37 INFO PythonRunner: Times: total = 8394, boot = -100, init = 112, finish = 8382
19/11/15 00:13:37 INFO Executor: Finished task 19.0 in stage 0.0 (TID 19). 1785 bytes result sent to driver
19/11/15 00:13:37 INFO CoarseGrainedExecutorBackend: Got assigned task 21
19/11/15 00:13:37 INFO Executor: Running task 21.0 in stage 0.0 (TID 21)
19/11/15 00:13:37 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:352321536+16777216
19/11/15 00:13:46 INFO PythonRunner: Times: total = 8291, boot = -63, init = 74, finish = 8280
19/11/15 00:13:46 INFO Executor: Finished task 21.0 in stage 0.0 (TID 21). 1699 bytes result sent to driver
19/11/15 00:13:46 INFO CoarseGrainedExecutorBackend: Got assigned task 23
19/11/15 00:13:46 INFO Executor: Running task 23.0 in stage 0.0 (TID 23)
19/11/15 00:13:46 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:385875968+16777216
19/11/15 00:13:54 INFO PythonRunner: Times: total = 8402, boot = -74, init = 90, finish = 8386
19/11/15 00:13:54 INFO Executor: Finished task 23.0 in stage 0.0 (TID 23). 1742 bytes result sent to driver
19/11/15 00:13:54 INFO CoarseGrainedExecutorBackend: Got assigned task 25
19/11/15 00:13:54 INFO Executor: Running task 25.0 in stage 0.0 (TID 25)
19/11/15 00:13:54 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:419430400+16777216
19/11/15 00:14:03 INFO PythonRunner: Times: total = 8327, boot = -54, init = 65, finish = 8316
19/11/15 00:14:03 INFO Executor: Finished task 25.0 in stage 0.0 (TID 25). 1742 bytes result sent to driver
19/11/15 00:14:03 INFO CoarseGrainedExecutorBackend: Got assigned task 27
19/11/15 00:14:03 INFO Executor: Running task 27.0 in stage 0.0 (TID 27)
19/11/15 00:14:03 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:452984832+16777216
19/11/15 00:14:11 INFO PythonRunner: Times: total = 8297, boot = -75, init = 86, finish = 8286
19/11/15 00:14:11 INFO Executor: Finished task 27.0 in stage 0.0 (TID 27). 1742 bytes result sent to driver
19/11/15 00:14:11 INFO CoarseGrainedExecutorBackend: Got assigned task 29
19/11/15 00:14:11 INFO Executor: Running task 29.0 in stage 0.0 (TID 29)
19/11/15 00:14:11 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:486539264+16777216
19/11/15 00:14:19 INFO PythonRunner: Times: total = 8285, boot = -71, init = 84, finish = 8272
19/11/15 00:14:19 INFO Executor: Finished task 29.0 in stage 0.0 (TID 29). 1742 bytes result sent to driver
19/11/15 00:14:19 INFO CoarseGrainedExecutorBackend: Got assigned task 31
19/11/15 00:14:19 INFO Executor: Running task 31.0 in stage 0.0 (TID 31)
19/11/15 00:14:19 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:520093696+16777216
19/11/15 00:14:28 INFO PythonRunner: Times: total = 8092, boot = -49, init = 60, finish = 8081
19/11/15 00:14:28 INFO Executor: Finished task 31.0 in stage 0.0 (TID 31). 1742 bytes result sent to driver
19/11/15 00:14:28 INFO CoarseGrainedExecutorBackend: Got assigned task 33
19/11/15 00:14:28 INFO Executor: Running task 1.0 in stage 1.0 (TID 33)
19/11/15 00:14:28 INFO MapOutputTrackerWorker: Updating epoch to 1 and clearing cache
19/11/15 00:14:28 INFO TorrentBroadcast: Started reading broadcast variable 2
19/11/15 00:14:28 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 29.6 KB, free 413.5 MB)
19/11/15 00:14:28 INFO TorrentBroadcast: Reading broadcast variable 2 took 23 ms
19/11/15 00:14:28 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 77.3 KB, free 413.5 MB)
19/11/15 00:14:28 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
19/11/15 00:14:28 INFO MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@master:39285)
19/11/15 00:14:28 INFO MapOutputTrackerWorker: Got the output locations
19/11/15 00:14:28 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/11/15 00:14:28 INFO TransportClientFactory: Successfully created connection to /172.23.0.3:39343 after 0 ms (0 ms spent in bootstraps)
19/11/15 00:14:28 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 12 ms
19/11/15 00:14:28 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/11/15 00:14:28 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/11/15 00:14:28 INFO PythonRunner: Times: total = 112, boot = -244, init = 355, finish = 1
19/11/15 00:14:28 INFO FileOutputCommitter: Saved output of task 'attempt_20191114161207_0008_m_000001_0' to hdfs://master:54310/output/_temporary/0/task_20191114161207_0008_m_000001
19/11/15 00:14:28 INFO SparkHadoopMapRedUtil: attempt_20191114161207_0008_m_000001_0: Committed
19/11/15 00:14:28 INFO Executor: Finished task 1.0 in stage 1.0 (TID 33). 2110 bytes result sent to driver
19/11/15 00:14:28 INFO CoarseGrainedExecutorBackend: Got assigned task 34
19/11/15 00:14:28 INFO Executor: Running task 2.0 in stage 1.0 (TID 34)
19/11/15 00:14:28 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/11/15 00:14:28 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 13 ms
19/11/15 00:14:28 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/11/15 00:14:28 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/11/15 00:14:28 INFO PythonRunner: Times: total = 67, boot = -282, init = 349, finish = 0
19/11/15 00:14:28 INFO FileOutputCommitter: Saved output of task 'attempt_20191114161207_0008_m_000002_0' to hdfs://master:54310/output/_temporary/0/task_20191114161207_0008_m_000002
19/11/15 00:14:28 INFO SparkHadoopMapRedUtil: attempt_20191114161207_0008_m_000002_0: Committed
19/11/15 00:14:28 INFO Executor: Finished task 2.0 in stage 1.0 (TID 34). 2024 bytes result sent to driver
19/11/15 00:14:28 INFO CoarseGrainedExecutorBackend: Got assigned task 36
19/11/15 00:14:28 INFO Executor: Running task 4.0 in stage 1.0 (TID 36)
19/11/15 00:14:28 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/11/15 00:14:28 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 12 ms
19/11/15 00:14:28 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/11/15 00:14:28 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/11/15 00:14:29 INFO PythonRunner: Times: total = 68, boot = -96, init = 164, finish = 0
19/11/15 00:14:29 INFO FileOutputCommitter: Saved output of task 'attempt_20191114161207_0008_m_000004_0' to hdfs://master:54310/output/_temporary/0/task_20191114161207_0008_m_000004
19/11/15 00:14:29 INFO SparkHadoopMapRedUtil: attempt_20191114161207_0008_m_000004_0: Committed
19/11/15 00:14:29 INFO Executor: Finished task 4.0 in stage 1.0 (TID 36). 2024 bytes result sent to driver
19/11/15 00:14:29 INFO CoarseGrainedExecutorBackend: Got assigned task 38
19/11/15 00:14:29 INFO Executor: Running task 6.0 in stage 1.0 (TID 38)
19/11/15 00:14:29 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/11/15 00:14:29 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 5 ms
19/11/15 00:14:29 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/11/15 00:14:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/11/15 00:14:29 INFO PythonRunner: Times: total = 66, boot = -89, init = 154, finish = 1
19/11/15 00:14:29 INFO FileOutputCommitter: Saved output of task 'attempt_20191114161207_0008_m_000006_0' to hdfs://master:54310/output/_temporary/0/task_20191114161207_0008_m_000006
19/11/15 00:14:29 INFO SparkHadoopMapRedUtil: attempt_20191114161207_0008_m_000006_0: Committed
19/11/15 00:14:29 INFO Executor: Finished task 6.0 in stage 1.0 (TID 38). 2067 bytes result sent to driver
19/11/15 00:14:29 INFO CoarseGrainedExecutorBackend: Got assigned task 40
19/11/15 00:14:29 INFO Executor: Running task 8.0 in stage 1.0 (TID 40)
19/11/15 00:14:29 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/11/15 00:14:29 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 1 ms
19/11/15 00:14:29 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/11/15 00:14:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/11/15 00:14:29 INFO PythonRunner: Times: total = 75, boot = -130, init = 205, finish = 0
19/11/15 00:14:29 INFO FileOutputCommitter: Saved output of task 'attempt_20191114161207_0008_m_000008_0' to hdfs://master:54310/output/_temporary/0/task_20191114161207_0008_m_000008
19/11/15 00:14:29 INFO SparkHadoopMapRedUtil: attempt_20191114161207_0008_m_000008_0: Committed
19/11/15 00:14:29 INFO Executor: Finished task 8.0 in stage 1.0 (TID 40). 2024 bytes result sent to driver
19/11/15 00:14:29 INFO CoarseGrainedExecutorBackend: Got assigned task 42
19/11/15 00:14:29 INFO Executor: Running task 10.0 in stage 1.0 (TID 42)
19/11/15 00:14:29 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/11/15 00:14:29 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 8 ms
19/11/15 00:14:29 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/11/15 00:14:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/11/15 00:14:29 INFO PythonRunner: Times: total = 66, boot = -131, init = 197, finish = 0
19/11/15 00:14:29 INFO FileOutputCommitter: Saved output of task 'attempt_20191114161207_0008_m_000010_0' to hdfs://master:54310/output/_temporary/0/task_20191114161207_0008_m_000010
19/11/15 00:14:29 INFO SparkHadoopMapRedUtil: attempt_20191114161207_0008_m_000010_0: Committed
19/11/15 00:14:29 INFO Executor: Finished task 10.0 in stage 1.0 (TID 42). 2024 bytes result sent to driver
19/11/15 00:14:29 INFO CoarseGrainedExecutorBackend: Got assigned task 44
19/11/15 00:14:29 INFO Executor: Running task 12.0 in stage 1.0 (TID 44)
19/11/15 00:14:29 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/11/15 00:14:29 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 13 ms
19/11/15 00:14:29 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/11/15 00:14:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/11/15 00:14:29 INFO PythonRunner: Times: total = 81, boot = -112, init = 193, finish = 0
19/11/15 00:14:29 INFO FileOutputCommitter: Saved output of task 'attempt_20191114161207_0008_m_000012_0' to hdfs://master:54310/output/_temporary/0/task_20191114161207_0008_m_000012
19/11/15 00:14:29 INFO SparkHadoopMapRedUtil: attempt_20191114161207_0008_m_000012_0: Committed
19/11/15 00:14:29 INFO Executor: Finished task 12.0 in stage 1.0 (TID 44). 2024 bytes result sent to driver
19/11/15 00:14:29 INFO CoarseGrainedExecutorBackend: Got assigned task 46
19/11/15 00:14:29 INFO Executor: Running task 14.0 in stage 1.0 (TID 46)
19/11/15 00:14:29 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/11/15 00:14:29 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 1 ms
19/11/15 00:14:29 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/11/15 00:14:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/11/15 00:14:29 INFO PythonRunner: Times: total = 65, boot = -93, init = 157, finish = 1
19/11/15 00:14:30 INFO FileOutputCommitter: Saved output of task 'attempt_20191114161207_0008_m_000014_0' to hdfs://master:54310/output/_temporary/0/task_20191114161207_0008_m_000014
19/11/15 00:14:30 INFO SparkHadoopMapRedUtil: attempt_20191114161207_0008_m_000014_0: Committed
19/11/15 00:14:30 INFO Executor: Finished task 14.0 in stage 1.0 (TID 46). 2024 bytes result sent to driver
19/11/15 00:14:30 INFO CoarseGrainedExecutorBackend: Got assigned task 48
19/11/15 00:14:30 INFO Executor: Running task 16.0 in stage 1.0 (TID 48)
19/11/15 00:14:30 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/11/15 00:14:30 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 2 ms
19/11/15 00:14:30 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/11/15 00:14:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/11/15 00:14:30 INFO PythonRunner: Times: total = 64, boot = -110, init = 173, finish = 1
19/11/15 00:14:30 INFO FileOutputCommitter: Saved output of task 'attempt_20191114161207_0008_m_000016_0' to hdfs://master:54310/output/_temporary/0/task_20191114161207_0008_m_000016
19/11/15 00:14:30 INFO SparkHadoopMapRedUtil: attempt_20191114161207_0008_m_000016_0: Committed
19/11/15 00:14:30 INFO Executor: Finished task 16.0 in stage 1.0 (TID 48). 2067 bytes result sent to driver
19/11/15 00:14:30 INFO CoarseGrainedExecutorBackend: Got assigned task 50
19/11/15 00:14:30 INFO Executor: Running task 18.0 in stage 1.0 (TID 50)
19/11/15 00:14:30 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/11/15 00:14:30 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 19 ms
19/11/15 00:14:30 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/11/15 00:14:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/11/15 00:14:30 INFO PythonRunner: Times: total = 71, boot = -132, init = 203, finish = 0
19/11/15 00:14:30 INFO FileOutputCommitter: Saved output of task 'attempt_20191114161207_0008_m_000018_0' to hdfs://master:54310/output/_temporary/0/task_20191114161207_0008_m_000018
19/11/15 00:14:30 INFO SparkHadoopMapRedUtil: attempt_20191114161207_0008_m_000018_0: Committed
19/11/15 00:14:30 INFO Executor: Finished task 18.0 in stage 1.0 (TID 50). 2024 bytes result sent to driver
19/11/15 00:14:30 INFO CoarseGrainedExecutorBackend: Got assigned task 52
19/11/15 00:14:30 INFO Executor: Running task 20.0 in stage 1.0 (TID 52)
19/11/15 00:14:30 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/11/15 00:14:30 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 1 ms
19/11/15 00:14:30 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/11/15 00:14:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/11/15 00:14:30 INFO PythonRunner: Times: total = 77, boot = -92, init = 169, finish = 0
19/11/15 00:14:30 INFO FileOutputCommitter: Saved output of task 'attempt_20191114161207_0008_m_000020_0' to hdfs://master:54310/output/_temporary/0/task_20191114161207_0008_m_000020
19/11/15 00:14:30 INFO SparkHadoopMapRedUtil: attempt_20191114161207_0008_m_000020_0: Committed
19/11/15 00:14:30 INFO Executor: Finished task 20.0 in stage 1.0 (TID 52). 2024 bytes result sent to driver
19/11/15 00:14:30 INFO CoarseGrainedExecutorBackend: Got assigned task 54
19/11/15 00:14:30 INFO Executor: Running task 22.0 in stage 1.0 (TID 54)
19/11/15 00:14:30 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/11/15 00:14:30 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 1 ms
19/11/15 00:14:30 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/11/15 00:14:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/11/15 00:14:30 INFO PythonRunner: Times: total = 73, boot = -131, init = 204, finish = 0
19/11/15 00:14:30 INFO FileOutputCommitter: Saved output of task 'attempt_20191114161207_0008_m_000022_0' to hdfs://master:54310/output/_temporary/0/task_20191114161207_0008_m_000022
19/11/15 00:14:30 INFO SparkHadoopMapRedUtil: attempt_20191114161207_0008_m_000022_0: Committed
19/11/15 00:14:30 INFO Executor: Finished task 22.0 in stage 1.0 (TID 54). 2024 bytes result sent to driver
19/11/15 00:14:30 INFO CoarseGrainedExecutorBackend: Got assigned task 57
19/11/15 00:14:30 INFO Executor: Running task 25.0 in stage 1.0 (TID 57)
19/11/15 00:14:30 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/11/15 00:14:30 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 2 ms
19/11/15 00:14:30 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/11/15 00:14:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/11/15 00:14:30 INFO PythonRunner: Times: total = 72, boot = -109, init = 181, finish = 0
19/11/15 00:14:31 INFO FileOutputCommitter: Saved output of task 'attempt_20191114161207_0008_m_000025_0' to hdfs://master:54310/output/_temporary/0/task_20191114161207_0008_m_000025
19/11/15 00:14:31 INFO SparkHadoopMapRedUtil: attempt_20191114161207_0008_m_000025_0: Committed
19/11/15 00:14:31 INFO Executor: Finished task 25.0 in stage 1.0 (TID 57). 2024 bytes result sent to driver
19/11/15 00:14:31 INFO CoarseGrainedExecutorBackend: Got assigned task 58
19/11/15 00:14:31 INFO Executor: Running task 26.0 in stage 1.0 (TID 58)
19/11/15 00:14:31 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/11/15 00:14:31 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 7 ms
19/11/15 00:14:31 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/11/15 00:14:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/11/15 00:14:31 INFO PythonRunner: Times: total = 61, boot = -87, init = 147, finish = 1
19/11/15 00:14:31 INFO FileOutputCommitter: Saved output of task 'attempt_20191114161207_0008_m_000026_0' to hdfs://master:54310/output/_temporary/0/task_20191114161207_0008_m_000026
19/11/15 00:14:31 INFO SparkHadoopMapRedUtil: attempt_20191114161207_0008_m_000026_0: Committed
19/11/15 00:14:31 INFO Executor: Finished task 26.0 in stage 1.0 (TID 58). 2024 bytes result sent to driver
19/11/15 00:14:31 INFO CoarseGrainedExecutorBackend: Got assigned task 59
19/11/15 00:14:31 INFO Executor: Running task 27.0 in stage 1.0 (TID 59)
19/11/15 00:14:31 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/11/15 00:14:31 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 11 ms
19/11/15 00:14:31 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/11/15 00:14:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/11/15 00:14:31 INFO PythonRunner: Times: total = 65, boot = -80, init = 145, finish = 0
19/11/15 00:14:31 INFO FileOutputCommitter: Saved output of task 'attempt_20191114161207_0008_m_000027_0' to hdfs://master:54310/output/_temporary/0/task_20191114161207_0008_m_000027
19/11/15 00:14:31 INFO SparkHadoopMapRedUtil: attempt_20191114161207_0008_m_000027_0: Committed
19/11/15 00:14:31 INFO Executor: Finished task 27.0 in stage 1.0 (TID 59). 2024 bytes result sent to driver
19/11/15 00:14:31 INFO CoarseGrainedExecutorBackend: Got assigned task 60
19/11/15 00:14:31 INFO Executor: Running task 29.0 in stage 1.0 (TID 60)
19/11/15 00:14:31 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/11/15 00:14:31 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 3 ms
19/11/15 00:14:31 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/11/15 00:14:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/11/15 00:14:31 INFO PythonRunner: Times: total = 69, boot = -80, init = 149, finish = 0
19/11/15 00:14:31 INFO FileOutputCommitter: Saved output of task 'attempt_20191114161207_0008_m_000029_0' to hdfs://master:54310/output/_temporary/0/task_20191114161207_0008_m_000029
19/11/15 00:14:31 INFO SparkHadoopMapRedUtil: attempt_20191114161207_0008_m_000029_0: Committed
19/11/15 00:14:31 INFO Executor: Finished task 29.0 in stage 1.0 (TID 60). 2024 bytes result sent to driver
19/11/15 00:14:31 INFO CoarseGrainedExecutorBackend: Got assigned task 61
19/11/15 00:14:31 INFO Executor: Running task 30.0 in stage 1.0 (TID 61)
19/11/15 00:14:31 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/11/15 00:14:31 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 8 ms
19/11/15 00:14:31 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/11/15 00:14:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/11/15 00:14:31 INFO PythonRunner: Times: total = 53, boot = -61, init = 114, finish = 0
19/11/15 00:14:31 INFO FileOutputCommitter: Saved output of task 'attempt_20191114161207_0008_m_000030_0' to hdfs://master:54310/output/_temporary/0/task_20191114161207_0008_m_000030
19/11/15 00:14:31 INFO SparkHadoopMapRedUtil: attempt_20191114161207_0008_m_000030_0: Committed
19/11/15 00:14:31 INFO Executor: Finished task 30.0 in stage 1.0 (TID 61). 2024 bytes result sent to driver
19/11/15 00:14:31 INFO CoarseGrainedExecutorBackend: Got assigned task 63
19/11/15 00:14:31 INFO Executor: Running task 28.0 in stage 1.0 (TID 63)
19/11/15 00:14:31 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
19/11/15 00:14:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/11/15 00:14:31 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/11/15 00:14:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/11/15 00:14:31 INFO PythonRunner: Times: total = 84, boot = -117, init = 201, finish = 0
19/11/15 00:14:31 INFO FileOutputCommitter: Saved output of task 'attempt_20191114161207_0008_m_000028_0' to hdfs://master:54310/output/_temporary/0/task_20191114161207_0008_m_000028
19/11/15 00:14:31 INFO SparkHadoopMapRedUtil: attempt_20191114161207_0008_m_000028_0: Committed
19/11/15 00:14:31 INFO Executor: Finished task 28.0 in stage 1.0 (TID 63). 1938 bytes result sent to driver
19/11/15 00:14:32 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
19/11/15 00:14:32 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
tdown
