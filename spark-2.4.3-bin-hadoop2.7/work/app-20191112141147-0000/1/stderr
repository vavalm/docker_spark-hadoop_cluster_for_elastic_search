Spark Executor Command: "/usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java" "-cp" "/root/spark/conf/:/root/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=46867" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@master:46867" "--executor-id" "1" "--hostname" "172.23.0.4" "--cores" "1" "--app-id" "app-20191112141147-0000" "--worker-url" "spark://Worker@172.23.0.4:36391"
========================================

Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
19/11/12 22:11:49 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 226@slave2
19/11/12 22:11:49 INFO SignalUtils: Registered signal handler for TERM
19/11/12 22:11:49 INFO SignalUtils: Registered signal handler for HUP
19/11/12 22:11:49 INFO SignalUtils: Registered signal handler for INT
19/11/12 22:11:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/11/12 22:11:49 INFO SecurityManager: Changing view acls to: root
19/11/12 22:11:49 INFO SecurityManager: Changing modify acls to: root
19/11/12 22:11:49 INFO SecurityManager: Changing view acls groups to: 
19/11/12 22:11:49 INFO SecurityManager: Changing modify acls groups to: 
19/11/12 22:11:49 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/11/12 22:11:50 INFO TransportClientFactory: Successfully created connection to master/172.23.0.2:46867 after 127 ms (0 ms spent in bootstraps)
19/11/12 22:11:50 INFO SecurityManager: Changing view acls to: root
19/11/12 22:11:50 INFO SecurityManager: Changing modify acls to: root
19/11/12 22:11:50 INFO SecurityManager: Changing view acls groups to: 
19/11/12 22:11:50 INFO SecurityManager: Changing modify acls groups to: 
19/11/12 22:11:50 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/11/12 22:11:50 INFO TransportClientFactory: Successfully created connection to master/172.23.0.2:46867 after 2 ms (0 ms spent in bootstraps)
19/11/12 22:11:50 INFO DiskBlockManager: Created local directory at /tmp/spark-f5bcb8c8-28de-4ac8-a023-eee5ceff8c73/executor-710f9bc9-ff89-48e1-91f0-c5daf0ee7417/blockmgr-3fefbfe1-fc05-4c64-b45b-1c731c2d2c98
19/11/12 22:11:50 INFO MemoryStore: MemoryStore started with capacity 413.9 MB
19/11/12 22:11:51 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@master:46867
19/11/12 22:11:51 INFO WorkerWatcher: Connecting to worker spark://Worker@172.23.0.4:36391
19/11/12 22:11:51 INFO WorkerWatcher: Successfully connected to spark://Worker@172.23.0.4:36391
19/11/12 22:11:51 INFO TransportClientFactory: Successfully created connection to /172.23.0.4:36391 after 8 ms (0 ms spent in bootstraps)
19/11/12 22:11:51 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
19/11/12 22:11:51 INFO Executor: Starting executor ID 1 on host 172.23.0.4
19/11/12 22:11:51 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44745.
19/11/12 22:11:51 INFO NettyBlockTransferService: Server created on 172.23.0.4:44745
19/11/12 22:11:51 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/11/12 22:11:51 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(1, 172.23.0.4, 44745, None)
19/11/12 22:11:51 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(1, 172.23.0.4, 44745, None)
19/11/12 22:11:51 INFO BlockManager: Initialized BlockManager: BlockManagerId(1, 172.23.0.4, 44745, None)
19/11/12 22:11:51 INFO CoarseGrainedExecutorBackend: Got assigned task 1
19/11/12 22:11:51 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
19/11/12 22:11:51 INFO TorrentBroadcast: Started reading broadcast variable 1
19/11/12 22:11:51 INFO TransportClientFactory: Successfully created connection to master/172.23.0.2:34235 after 21 ms (0 ms spent in bootstraps)
19/11/12 22:11:51 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.2 KB, free 413.9 MB)
19/11/12 22:11:51 INFO TorrentBroadcast: Reading broadcast variable 1 took 112 ms
19/11/12 22:11:51 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.1 KB, free 413.9 MB)
19/11/12 22:11:52 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:16777216+16777216
19/11/12 22:11:52 INFO TorrentBroadcast: Started reading broadcast variable 0
19/11/12 22:11:52 INFO TransportClientFactory: Successfully created connection to /172.23.0.3:38583 after 0 ms (0 ms spent in bootstraps)
19/11/12 22:11:52 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.9 KB, free 413.9 MB)
19/11/12 22:11:52 INFO TorrentBroadcast: Reading broadcast variable 0 took 75 ms
19/11/12 22:11:52 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 320.9 KB, free 413.6 MB)
19/11/12 22:12:03 INFO PythonRunner: Times: total = 9542, boot = 893, init = 51, finish = 8598
19/11/12 22:12:03 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1742 bytes result sent to driver
19/11/12 22:12:03 INFO CoarseGrainedExecutorBackend: Got assigned task 3
19/11/12 22:12:03 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
19/11/12 22:12:03 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:50331648+16777216
19/11/12 22:12:11 INFO PythonRunner: Times: total = 8276, boot = -697, init = 732, finish = 8241
19/11/12 22:12:11 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1742 bytes result sent to driver
19/11/12 22:12:11 INFO CoarseGrainedExecutorBackend: Got assigned task 5
19/11/12 22:12:11 INFO Executor: Running task 5.0 in stage 0.0 (TID 5)
19/11/12 22:12:11 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:83886080+16777216
19/11/12 22:12:20 INFO PythonRunner: Times: total = 8601, boot = -168, init = 179, finish = 8590
19/11/12 22:12:20 INFO Executor: Finished task 5.0 in stage 0.0 (TID 5). 1742 bytes result sent to driver
19/11/12 22:12:20 INFO CoarseGrainedExecutorBackend: Got assigned task 7
19/11/12 22:12:20 INFO Executor: Running task 7.0 in stage 0.0 (TID 7)
19/11/12 22:12:20 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:117440512+16777216
19/11/12 22:12:29 INFO PythonRunner: Times: total = 8426, boot = -131, init = 157, finish = 8400
19/11/12 22:12:29 INFO Executor: Finished task 7.0 in stage 0.0 (TID 7). 1742 bytes result sent to driver
19/11/12 22:12:29 INFO CoarseGrainedExecutorBackend: Got assigned task 9
19/11/12 22:12:29 INFO Executor: Running task 9.0 in stage 0.0 (TID 9)
19/11/12 22:12:29 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:150994944+16777216
19/11/12 22:12:37 INFO PythonRunner: Times: total = 8332, boot = -117, init = 143, finish = 8306
19/11/12 22:12:37 INFO Executor: Finished task 9.0 in stage 0.0 (TID 9). 1742 bytes result sent to driver
19/11/12 22:12:37 INFO CoarseGrainedExecutorBackend: Got assigned task 11
19/11/12 22:12:37 INFO Executor: Running task 11.0 in stage 0.0 (TID 11)
19/11/12 22:12:37 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:184549376+16777216
19/11/12 22:12:46 INFO PythonRunner: Times: total = 8188, boot = -105, init = 116, finish = 8177
19/11/12 22:12:46 INFO Executor: Finished task 11.0 in stage 0.0 (TID 11). 1742 bytes result sent to driver
19/11/12 22:12:46 INFO CoarseGrainedExecutorBackend: Got assigned task 13
19/11/12 22:12:46 INFO Executor: Running task 13.0 in stage 0.0 (TID 13)
19/11/12 22:12:46 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:218103808+16777216
19/11/12 22:12:54 INFO PythonRunner: Times: total = 8748, boot = -101, init = 130, finish = 8719
19/11/12 22:12:55 INFO Executor: Finished task 13.0 in stage 0.0 (TID 13). 1742 bytes result sent to driver
19/11/12 22:12:55 INFO CoarseGrainedExecutorBackend: Got assigned task 15
19/11/12 22:12:55 INFO Executor: Running task 15.0 in stage 0.0 (TID 15)
19/11/12 22:12:55 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:251658240+16777216
19/11/12 22:13:03 INFO PythonRunner: Times: total = 8401, boot = -77, init = 112, finish = 8366
19/11/12 22:13:03 INFO Executor: Finished task 15.0 in stage 0.0 (TID 15). 1742 bytes result sent to driver
19/11/12 22:13:03 INFO CoarseGrainedExecutorBackend: Got assigned task 17
19/11/12 22:13:03 INFO Executor: Running task 17.0 in stage 0.0 (TID 17)
19/11/12 22:13:03 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:285212672+16777216
19/11/12 22:13:12 INFO PythonRunner: Times: total = 8351, boot = -92, init = 119, finish = 8324
19/11/12 22:13:12 INFO Executor: Finished task 17.0 in stage 0.0 (TID 17). 1742 bytes result sent to driver
19/11/12 22:13:12 INFO CoarseGrainedExecutorBackend: Got assigned task 19
19/11/12 22:13:12 INFO Executor: Running task 19.0 in stage 0.0 (TID 19)
19/11/12 22:13:12 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:318767104+16777216
19/11/12 22:13:20 INFO PythonRunner: Times: total = 8322, boot = -114, init = 126, finish = 8310
19/11/12 22:13:20 INFO Executor: Finished task 19.0 in stage 0.0 (TID 19). 1742 bytes result sent to driver
19/11/12 22:13:20 INFO CoarseGrainedExecutorBackend: Got assigned task 20
19/11/12 22:13:20 INFO Executor: Running task 20.0 in stage 0.0 (TID 20)
19/11/12 22:13:20 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:335544320+16777216
19/11/12 22:13:28 INFO PythonRunner: Times: total = 8412, boot = -56, init = 68, finish = 8400
19/11/12 22:13:28 INFO Executor: Finished task 20.0 in stage 0.0 (TID 20). 1742 bytes result sent to driver
19/11/12 22:13:28 INFO CoarseGrainedExecutorBackend: Got assigned task 23
19/11/12 22:13:28 INFO Executor: Running task 23.0 in stage 0.0 (TID 23)
19/11/12 22:13:28 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:385875968+16777216
19/11/12 22:13:37 INFO PythonRunner: Times: total = 8481, boot = -109, init = 119, finish = 8471
19/11/12 22:13:37 INFO Executor: Finished task 23.0 in stage 0.0 (TID 23). 1742 bytes result sent to driver
19/11/12 22:13:37 INFO CoarseGrainedExecutorBackend: Got assigned task 24
19/11/12 22:13:37 INFO Executor: Running task 24.0 in stage 0.0 (TID 24)
19/11/12 22:13:37 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:402653184+16777216
19/11/12 22:13:46 INFO PythonRunner: Times: total = 8620, boot = -47, init = 57, finish = 8610
19/11/12 22:13:46 INFO Executor: Finished task 24.0 in stage 0.0 (TID 24). 1742 bytes result sent to driver
19/11/12 22:13:46 INFO CoarseGrainedExecutorBackend: Got assigned task 26
19/11/12 22:13:46 INFO Executor: Running task 26.0 in stage 0.0 (TID 26)
19/11/12 22:13:46 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:436207616+16777216
19/11/12 22:13:54 INFO PythonRunner: Times: total = 8473, boot = -52, init = 63, finish = 8462
19/11/12 22:13:54 INFO Executor: Finished task 26.0 in stage 0.0 (TID 26). 1742 bytes result sent to driver
19/11/12 22:13:54 INFO CoarseGrainedExecutorBackend: Got assigned task 28
19/11/12 22:13:54 INFO Executor: Running task 28.0 in stage 0.0 (TID 28)
19/11/12 22:13:54 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:469762048+16777216
19/11/12 22:14:03 INFO PythonRunner: Times: total = 8552, boot = -77, init = 87, finish = 8542
19/11/12 22:14:03 INFO Executor: Finished task 28.0 in stage 0.0 (TID 28). 1742 bytes result sent to driver
19/11/12 22:14:03 INFO CoarseGrainedExecutorBackend: Got assigned task 31
19/11/12 22:14:03 INFO Executor: Running task 31.0 in stage 0.0 (TID 31)
19/11/12 22:14:03 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:520093696+16777216
19/11/12 22:14:11 INFO PythonRunner: Times: total = 8303, boot = -61, init = 72, finish = 8292
19/11/12 22:14:11 INFO Executor: Finished task 31.0 in stage 0.0 (TID 31). 1742 bytes result sent to driver
19/11/12 22:14:11 INFO CoarseGrainedExecutorBackend: Got assigned task 32
19/11/12 22:14:11 INFO Executor: Running task 0.0 in stage 1.0 (TID 32)
19/11/12 22:14:11 INFO MapOutputTrackerWorker: Updating epoch to 1 and clearing cache
19/11/12 22:14:11 INFO TorrentBroadcast: Started reading broadcast variable 2
19/11/12 22:14:12 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 29.6 KB, free 413.5 MB)
19/11/12 22:14:12 INFO TorrentBroadcast: Reading broadcast variable 2 took 28 ms
19/11/12 22:14:12 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 77.3 KB, free 413.5 MB)
19/11/12 22:14:12 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
19/11/12 22:14:12 INFO MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@master:46867)
19/11/12 22:14:12 INFO MapOutputTrackerWorker: Got the output locations
19/11/12 22:14:12 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/11/12 22:14:12 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 42 ms
19/11/12 22:14:12 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/11/12 22:14:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/11/12 22:14:12 INFO PythonRunner: Times: total = 100, boot = -295, init = 394, finish = 1
19/11/12 22:14:12 INFO FileOutputCommitter: Saved output of task 'attempt_20191112141150_0008_m_000000_0' to hdfs://master:54310/output/_temporary/0/task_20191112141150_0008_m_000000
19/11/12 22:14:12 INFO SparkHadoopMapRedUtil: attempt_20191112141150_0008_m_000000_0: Committed
19/11/12 22:14:12 INFO Executor: Finished task 0.0 in stage 1.0 (TID 32). 2110 bytes result sent to driver
19/11/12 22:14:12 INFO CoarseGrainedExecutorBackend: Got assigned task 35
19/11/12 22:14:12 INFO Executor: Running task 3.0 in stage 1.0 (TID 35)
19/11/12 22:14:12 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/11/12 22:14:12 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 9 ms
19/11/12 22:14:12 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/11/12 22:14:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/11/12 22:14:12 INFO PythonRunner: Times: total = 63, boot = -292, init = 354, finish = 1
19/11/12 22:14:12 INFO FileOutputCommitter: Saved output of task 'attempt_20191112141150_0008_m_000003_0' to hdfs://master:54310/output/_temporary/0/task_20191112141150_0008_m_000003
19/11/12 22:14:12 INFO SparkHadoopMapRedUtil: attempt_20191112141150_0008_m_000003_0: Committed
19/11/12 22:14:12 INFO Executor: Finished task 3.0 in stage 1.0 (TID 35). 2024 bytes result sent to driver
19/11/12 22:14:12 INFO CoarseGrainedExecutorBackend: Got assigned task 36
19/11/12 22:14:12 INFO Executor: Running task 4.0 in stage 1.0 (TID 36)
19/11/12 22:14:12 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/11/12 22:14:12 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 12 ms
19/11/12 22:14:12 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/11/12 22:14:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/11/12 22:14:12 INFO PythonRunner: Times: total = 59, boot = -135, init = 193, finish = 1
19/11/12 22:14:12 INFO FileOutputCommitter: Saved output of task 'attempt_20191112141150_0008_m_000004_0' to hdfs://master:54310/output/_temporary/0/task_20191112141150_0008_m_000004
19/11/12 22:14:12 INFO SparkHadoopMapRedUtil: attempt_20191112141150_0008_m_000004_0: Committed
19/11/12 22:14:12 INFO Executor: Finished task 4.0 in stage 1.0 (TID 36). 2024 bytes result sent to driver
19/11/12 22:14:12 INFO CoarseGrainedExecutorBackend: Got assigned task 38
19/11/12 22:14:12 INFO Executor: Running task 6.0 in stage 1.0 (TID 38)
19/11/12 22:14:12 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/11/12 22:14:12 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 10 ms
19/11/12 22:14:12 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/11/12 22:14:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/11/12 22:14:13 INFO PythonRunner: Times: total = 79, boot = -103, init = 181, finish = 1
19/11/12 22:14:13 INFO FileOutputCommitter: Saved output of task 'attempt_20191112141150_0008_m_000006_0' to hdfs://master:54310/output/_temporary/0/task_20191112141150_0008_m_000006
19/11/12 22:14:13 INFO SparkHadoopMapRedUtil: attempt_20191112141150_0008_m_000006_0: Committed
19/11/12 22:14:13 INFO Executor: Finished task 6.0 in stage 1.0 (TID 38). 2024 bytes result sent to driver
19/11/12 22:14:13 INFO CoarseGrainedExecutorBackend: Got assigned task 40
19/11/12 22:14:13 INFO Executor: Running task 8.0 in stage 1.0 (TID 40)
19/11/12 22:14:13 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/11/12 22:14:13 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 11 ms
19/11/12 22:14:13 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/11/12 22:14:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/11/12 22:14:13 INFO PythonRunner: Times: total = 73, boot = -106, init = 178, finish = 1
19/11/12 22:14:13 INFO FileOutputCommitter: Saved output of task 'attempt_20191112141150_0008_m_000008_0' to hdfs://master:54310/output/_temporary/0/task_20191112141150_0008_m_000008
19/11/12 22:14:13 INFO SparkHadoopMapRedUtil: attempt_20191112141150_0008_m_000008_0: Committed
19/11/12 22:14:13 INFO Executor: Finished task 8.0 in stage 1.0 (TID 40). 2024 bytes result sent to driver
19/11/12 22:14:13 INFO CoarseGrainedExecutorBackend: Got assigned task 42
19/11/12 22:14:13 INFO Executor: Running task 10.0 in stage 1.0 (TID 42)
19/11/12 22:14:13 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/11/12 22:14:13 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 4 ms
19/11/12 22:14:13 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/11/12 22:14:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/11/12 22:14:13 INFO PythonRunner: Times: total = 71, boot = -57, init = 127, finish = 1
19/11/12 22:14:13 INFO FileOutputCommitter: Saved output of task 'attempt_20191112141150_0008_m_000010_0' to hdfs://master:54310/output/_temporary/0/task_20191112141150_0008_m_000010
19/11/12 22:14:13 INFO SparkHadoopMapRedUtil: attempt_20191112141150_0008_m_000010_0: Committed
19/11/12 22:14:13 INFO Executor: Finished task 10.0 in stage 1.0 (TID 42). 2024 bytes result sent to driver
19/11/12 22:14:13 INFO CoarseGrainedExecutorBackend: Got assigned task 44
19/11/12 22:14:13 INFO Executor: Running task 12.0 in stage 1.0 (TID 44)
19/11/12 22:14:13 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/11/12 22:14:13 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 6 ms
19/11/12 22:14:13 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/11/12 22:14:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/11/12 22:14:13 INFO PythonRunner: Times: total = 76, boot = -89, init = 164, finish = 1
19/11/12 22:14:13 INFO FileOutputCommitter: Saved output of task 'attempt_20191112141150_0008_m_000012_0' to hdfs://master:54310/output/_temporary/0/task_20191112141150_0008_m_000012
19/11/12 22:14:13 INFO SparkHadoopMapRedUtil: attempt_20191112141150_0008_m_000012_0: Committed
19/11/12 22:14:13 INFO Executor: Finished task 12.0 in stage 1.0 (TID 44). 2024 bytes result sent to driver
19/11/12 22:14:13 INFO CoarseGrainedExecutorBackend: Got assigned task 46
19/11/12 22:14:13 INFO Executor: Running task 14.0 in stage 1.0 (TID 46)
19/11/12 22:14:13 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/11/12 22:14:13 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 12 ms
19/11/12 22:14:13 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/11/12 22:14:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/11/12 22:14:13 INFO PythonRunner: Times: total = 83, boot = -101, init = 183, finish = 1
19/11/12 22:14:13 INFO FileOutputCommitter: Saved output of task 'attempt_20191112141150_0008_m_000014_0' to hdfs://master:54310/output/_temporary/0/task_20191112141150_0008_m_000014
19/11/12 22:14:13 INFO SparkHadoopMapRedUtil: attempt_20191112141150_0008_m_000014_0: Committed
19/11/12 22:14:13 INFO Executor: Finished task 14.0 in stage 1.0 (TID 46). 2024 bytes result sent to driver
19/11/12 22:14:13 INFO CoarseGrainedExecutorBackend: Got assigned task 48
19/11/12 22:14:13 INFO Executor: Running task 16.0 in stage 1.0 (TID 48)
19/11/12 22:14:13 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/11/12 22:14:13 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 18 ms
19/11/12 22:14:13 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/11/12 22:14:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/11/12 22:14:13 INFO PythonRunner: Times: total = 66, boot = -103, init = 168, finish = 1
19/11/12 22:14:14 INFO FileOutputCommitter: Saved output of task 'attempt_20191112141150_0008_m_000016_0' to hdfs://master:54310/output/_temporary/0/task_20191112141150_0008_m_000016
19/11/12 22:14:14 INFO SparkHadoopMapRedUtil: attempt_20191112141150_0008_m_000016_0: Committed
19/11/12 22:14:14 INFO Executor: Finished task 16.0 in stage 1.0 (TID 48). 2024 bytes result sent to driver
19/11/12 22:14:14 INFO CoarseGrainedExecutorBackend: Got assigned task 50
19/11/12 22:14:14 INFO Executor: Running task 18.0 in stage 1.0 (TID 50)
19/11/12 22:14:14 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/11/12 22:14:14 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 22 ms
19/11/12 22:14:14 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/11/12 22:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/11/12 22:14:14 INFO PythonRunner: Times: total = 72, boot = -174, init = 245, finish = 1
19/11/12 22:14:14 INFO FileOutputCommitter: Saved output of task 'attempt_20191112141150_0008_m_000018_0' to hdfs://master:54310/output/_temporary/0/task_20191112141150_0008_m_000018
19/11/12 22:14:14 INFO SparkHadoopMapRedUtil: attempt_20191112141150_0008_m_000018_0: Committed
19/11/12 22:14:14 INFO Executor: Finished task 18.0 in stage 1.0 (TID 50). 2067 bytes result sent to driver
19/11/12 22:14:14 INFO CoarseGrainedExecutorBackend: Got assigned task 52
19/11/12 22:14:14 INFO Executor: Running task 20.0 in stage 1.0 (TID 52)
19/11/12 22:14:14 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/11/12 22:14:14 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 1 ms
19/11/12 22:14:14 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/11/12 22:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/11/12 22:14:14 INFO PythonRunner: Times: total = 63, boot = -103, init = 165, finish = 1
19/11/12 22:14:14 INFO FileOutputCommitter: Saved output of task 'attempt_20191112141150_0008_m_000020_0' to hdfs://master:54310/output/_temporary/0/task_20191112141150_0008_m_000020
19/11/12 22:14:14 INFO SparkHadoopMapRedUtil: attempt_20191112141150_0008_m_000020_0: Committed
19/11/12 22:14:14 INFO Executor: Finished task 20.0 in stage 1.0 (TID 52). 2024 bytes result sent to driver
19/11/12 22:14:14 INFO CoarseGrainedExecutorBackend: Got assigned task 54
19/11/12 22:14:14 INFO Executor: Running task 22.0 in stage 1.0 (TID 54)
19/11/12 22:14:14 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/11/12 22:14:14 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 4 ms
19/11/12 22:14:14 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/11/12 22:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/11/12 22:14:14 INFO PythonRunner: Times: total = 67, boot = -82, init = 148, finish = 1
19/11/12 22:14:14 INFO FileOutputCommitter: Saved output of task 'attempt_20191112141150_0008_m_000022_0' to hdfs://master:54310/output/_temporary/0/task_20191112141150_0008_m_000022
19/11/12 22:14:14 INFO SparkHadoopMapRedUtil: attempt_20191112141150_0008_m_000022_0: Committed
19/11/12 22:14:14 INFO Executor: Finished task 22.0 in stage 1.0 (TID 54). 2024 bytes result sent to driver
19/11/12 22:14:14 INFO CoarseGrainedExecutorBackend: Got assigned task 56
19/11/12 22:14:14 INFO Executor: Running task 24.0 in stage 1.0 (TID 56)
19/11/12 22:14:14 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/11/12 22:14:14 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 2 ms
19/11/12 22:14:14 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/11/12 22:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/11/12 22:14:14 INFO PythonRunner: Times: total = 79, boot = -149, init = 227, finish = 1
19/11/12 22:14:14 INFO FileOutputCommitter: Saved output of task 'attempt_20191112141150_0008_m_000024_0' to hdfs://master:54310/output/_temporary/0/task_20191112141150_0008_m_000024
19/11/12 22:14:14 INFO SparkHadoopMapRedUtil: attempt_20191112141150_0008_m_000024_0: Committed
19/11/12 22:14:14 INFO Executor: Finished task 24.0 in stage 1.0 (TID 56). 2024 bytes result sent to driver
19/11/12 22:14:14 INFO CoarseGrainedExecutorBackend: Got assigned task 58
19/11/12 22:14:14 INFO Executor: Running task 26.0 in stage 1.0 (TID 58)
19/11/12 22:14:14 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/11/12 22:14:14 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 4 ms
19/11/12 22:14:14 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/11/12 22:14:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/11/12 22:14:14 INFO PythonRunner: Times: total = 82, boot = -116, init = 197, finish = 1
19/11/12 22:14:14 INFO FileOutputCommitter: Saved output of task 'attempt_20191112141150_0008_m_000026_0' to hdfs://master:54310/output/_temporary/0/task_20191112141150_0008_m_000026
19/11/12 22:14:14 INFO SparkHadoopMapRedUtil: attempt_20191112141150_0008_m_000026_0: Committed
19/11/12 22:14:14 INFO Executor: Finished task 26.0 in stage 1.0 (TID 58). 2024 bytes result sent to driver
19/11/12 22:14:14 INFO CoarseGrainedExecutorBackend: Got assigned task 60
19/11/12 22:14:14 INFO Executor: Running task 29.0 in stage 1.0 (TID 60)
19/11/12 22:14:15 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/11/12 22:14:15 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 9 ms
19/11/12 22:14:15 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/11/12 22:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/11/12 22:14:15 INFO PythonRunner: Times: total = 78, boot = -81, init = 158, finish = 1
19/11/12 22:14:15 INFO FileOutputCommitter: Saved output of task 'attempt_20191112141150_0008_m_000029_0' to hdfs://master:54310/output/_temporary/0/task_20191112141150_0008_m_000029
19/11/12 22:14:15 INFO SparkHadoopMapRedUtil: attempt_20191112141150_0008_m_000029_0: Committed
19/11/12 22:14:15 INFO Executor: Finished task 29.0 in stage 1.0 (TID 60). 2024 bytes result sent to driver
19/11/12 22:14:15 INFO CoarseGrainedExecutorBackend: Got assigned task 62
19/11/12 22:14:15 INFO Executor: Running task 31.0 in stage 1.0 (TID 62)
19/11/12 22:14:15 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/11/12 22:14:15 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 5 ms
19/11/12 22:14:15 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/11/12 22:14:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/11/12 22:14:15 INFO PythonRunner: Times: total = 63, boot = -84, init = 146, finish = 1
19/11/12 22:14:15 INFO FileOutputCommitter: Saved output of task 'attempt_20191112141150_0008_m_000031_0' to hdfs://master:54310/output/_temporary/0/task_20191112141150_0008_m_000031
19/11/12 22:14:15 INFO SparkHadoopMapRedUtil: attempt_20191112141150_0008_m_000031_0: Committed
19/11/12 22:14:15 INFO Executor: Finished task 31.0 in stage 1.0 (TID 62). 2024 bytes result sent to driver
19/11/12 22:14:15 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
19/11/12 22:14:15 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
tdown
