Spark Executor Command: "/usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java" "-cp" "/root/spark/conf/:/root/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=39269" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@master:39269" "--executor-id" "0" "--hostname" "172.23.0.4" "--cores" "1" "--app-id" "app-20191202094817-0000" "--worker-url" "spark://Worker@172.23.0.4:41641"
========================================

Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
19/12/02 17:48:18 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 239@slave2
19/12/02 17:48:18 INFO SignalUtils: Registered signal handler for TERM
19/12/02 17:48:18 INFO SignalUtils: Registered signal handler for HUP
19/12/02 17:48:18 INFO SignalUtils: Registered signal handler for INT
19/12/02 17:48:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/12/02 17:48:19 INFO SecurityManager: Changing view acls to: root
19/12/02 17:48:19 INFO SecurityManager: Changing modify acls to: root
19/12/02 17:48:19 INFO SecurityManager: Changing view acls groups to: 
19/12/02 17:48:19 INFO SecurityManager: Changing modify acls groups to: 
19/12/02 17:48:19 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/12/02 17:48:20 INFO TransportClientFactory: Successfully created connection to master/172.23.0.2:39269 after 119 ms (0 ms spent in bootstraps)
19/12/02 17:48:20 INFO SecurityManager: Changing view acls to: root
19/12/02 17:48:20 INFO SecurityManager: Changing modify acls to: root
19/12/02 17:48:20 INFO SecurityManager: Changing view acls groups to: 
19/12/02 17:48:20 INFO SecurityManager: Changing modify acls groups to: 
19/12/02 17:48:20 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/12/02 17:48:20 INFO TransportClientFactory: Successfully created connection to master/172.23.0.2:39269 after 10 ms (0 ms spent in bootstraps)
19/12/02 17:48:20 INFO DiskBlockManager: Created local directory at /tmp/spark-7ddcd2f7-d8ae-42fe-9684-cd5a55cdd2bf/executor-ae14695e-6478-47e7-aec2-f02e9c933540/blockmgr-280d42ea-4885-477e-a1fe-21e565230b13
19/12/02 17:48:20 INFO MemoryStore: MemoryStore started with capacity 413.9 MB
19/12/02 17:48:20 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@master:39269
19/12/02 17:48:20 INFO WorkerWatcher: Connecting to worker spark://Worker@172.23.0.4:41641
19/12/02 17:48:20 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
19/12/02 17:48:20 INFO Executor: Starting executor ID 0 on host 172.23.0.4
19/12/02 17:48:21 INFO WorkerWatcher: Successfully connected to spark://Worker@172.23.0.4:41641
19/12/02 17:48:21 INFO TransportClientFactory: Successfully created connection to /172.23.0.4:41641 after 29 ms (0 ms spent in bootstraps)
19/12/02 17:48:21 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34227.
19/12/02 17:48:21 INFO NettyBlockTransferService: Server created on 172.23.0.4:34227
19/12/02 17:48:21 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/12/02 17:48:21 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.23.0.4, 34227, None)
19/12/02 17:48:21 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.23.0.4, 34227, None)
19/12/02 17:48:21 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.23.0.4, 34227, None)
19/12/02 17:48:21 INFO CoarseGrainedExecutorBackend: Got assigned task 0
19/12/02 17:48:21 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
19/12/02 17:48:21 INFO TorrentBroadcast: Started reading broadcast variable 1
19/12/02 17:48:21 INFO TransportClientFactory: Successfully created connection to master/172.23.0.2:44967 after 18 ms (0 ms spent in bootstraps)
19/12/02 17:48:21 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.2 KB, free 413.9 MB)
19/12/02 17:48:21 INFO TorrentBroadcast: Reading broadcast variable 1 took 148 ms
19/12/02 17:48:21 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.1 KB, free 413.9 MB)
19/12/02 17:48:21 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:0+16777216
19/12/02 17:48:21 INFO TorrentBroadcast: Started reading broadcast variable 0
19/12/02 17:48:21 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.9 KB, free 413.9 MB)
19/12/02 17:48:21 INFO TorrentBroadcast: Reading broadcast variable 0 took 14 ms
19/12/02 17:48:21 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 320.9 KB, free 413.6 MB)
19/12/02 17:48:32 INFO PythonRunner: Times: total = 9399, boot = 878, init = 138, finish = 8383
19/12/02 17:48:32 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1785 bytes result sent to driver
19/12/02 17:48:33 INFO CoarseGrainedExecutorBackend: Got assigned task 3
19/12/02 17:48:33 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
19/12/02 17:48:33 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:50331648+16777216
19/12/02 17:48:41 INFO PythonRunner: Times: total = 8088, boot = -696, init = 723, finish = 8061
19/12/02 17:48:41 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1742 bytes result sent to driver
19/12/02 17:48:41 INFO CoarseGrainedExecutorBackend: Got assigned task 4
19/12/02 17:48:41 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
19/12/02 17:48:41 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:67108864+16777216
19/12/02 17:48:49 INFO PythonRunner: Times: total = 8172, boot = -180, init = 200, finish = 8152
19/12/02 17:48:49 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1742 bytes result sent to driver
19/12/02 17:48:49 INFO CoarseGrainedExecutorBackend: Got assigned task 6
19/12/02 17:48:49 INFO Executor: Running task 6.0 in stage 0.0 (TID 6)
19/12/02 17:48:49 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:100663296+16777216
19/12/02 17:48:58 INFO PythonRunner: Times: total = 8578, boot = -142, init = 176, finish = 8544
19/12/02 17:48:58 INFO Executor: Finished task 6.0 in stage 0.0 (TID 6). 1742 bytes result sent to driver
19/12/02 17:48:58 INFO CoarseGrainedExecutorBackend: Got assigned task 8
19/12/02 17:48:58 INFO Executor: Running task 8.0 in stage 0.0 (TID 8)
19/12/02 17:48:58 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:134217728+16777216
19/12/02 17:49:07 INFO PythonRunner: Times: total = 8518, boot = -95, init = 123, finish = 8490
19/12/02 17:49:07 INFO Executor: Finished task 8.0 in stage 0.0 (TID 8). 1742 bytes result sent to driver
19/12/02 17:49:07 INFO CoarseGrainedExecutorBackend: Got assigned task 10
19/12/02 17:49:07 INFO Executor: Running task 10.0 in stage 0.0 (TID 10)
19/12/02 17:49:07 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:167772160+16777216
19/12/02 17:49:15 INFO PythonRunner: Times: total = 8699, boot = -83, init = 93, finish = 8689
19/12/02 17:49:15 INFO Executor: Finished task 10.0 in stage 0.0 (TID 10). 1742 bytes result sent to driver
19/12/02 17:49:15 INFO CoarseGrainedExecutorBackend: Got assigned task 12
19/12/02 17:49:15 INFO Executor: Running task 12.0 in stage 0.0 (TID 12)
19/12/02 17:49:15 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:201326592+16777216
19/12/02 17:49:24 INFO PythonRunner: Times: total = 8268, boot = -91, init = 103, finish = 8256
19/12/02 17:49:24 INFO Executor: Finished task 12.0 in stage 0.0 (TID 12). 1742 bytes result sent to driver
19/12/02 17:49:24 INFO CoarseGrainedExecutorBackend: Got assigned task 14
19/12/02 17:49:24 INFO Executor: Running task 14.0 in stage 0.0 (TID 14)
19/12/02 17:49:24 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:234881024+16777216
19/12/02 17:49:32 INFO PythonRunner: Times: total = 8360, boot = -100, init = 149, finish = 8311
19/12/02 17:49:32 INFO Executor: Finished task 14.0 in stage 0.0 (TID 14). 1742 bytes result sent to driver
19/12/02 17:49:32 INFO CoarseGrainedExecutorBackend: Got assigned task 16
19/12/02 17:49:32 INFO Executor: Running task 16.0 in stage 0.0 (TID 16)
19/12/02 17:49:32 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:268435456+16777216
19/12/02 17:49:41 INFO PythonRunner: Times: total = 8394, boot = -78, init = 88, finish = 8384
19/12/02 17:49:41 INFO Executor: Finished task 16.0 in stage 0.0 (TID 16). 1699 bytes result sent to driver
19/12/02 17:49:41 INFO CoarseGrainedExecutorBackend: Got assigned task 18
19/12/02 17:49:41 INFO Executor: Running task 18.0 in stage 0.0 (TID 18)
19/12/02 17:49:41 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:301989888+16777216
19/12/02 17:49:49 INFO PythonRunner: Times: total = 8353, boot = -70, init = 81, finish = 8342
19/12/02 17:49:49 INFO Executor: Finished task 18.0 in stage 0.0 (TID 18). 1742 bytes result sent to driver
19/12/02 17:49:49 INFO CoarseGrainedExecutorBackend: Got assigned task 20
19/12/02 17:49:49 INFO Executor: Running task 20.0 in stage 0.0 (TID 20)
19/12/02 17:49:49 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:335544320+16777216
19/12/02 17:49:58 INFO PythonRunner: Times: total = 8287, boot = -90, init = 102, finish = 8275
19/12/02 17:49:58 INFO Executor: Finished task 20.0 in stage 0.0 (TID 20). 1699 bytes result sent to driver
19/12/02 17:49:58 INFO CoarseGrainedExecutorBackend: Got assigned task 22
19/12/02 17:49:58 INFO Executor: Running task 22.0 in stage 0.0 (TID 22)
19/12/02 17:49:58 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:369098752+16777216
19/12/02 17:50:06 INFO PythonRunner: Times: total = 8273, boot = -59, init = 70, finish = 8262
19/12/02 17:50:06 INFO Executor: Finished task 22.0 in stage 0.0 (TID 22). 1699 bytes result sent to driver
19/12/02 17:50:06 INFO CoarseGrainedExecutorBackend: Got assigned task 24
19/12/02 17:50:06 INFO Executor: Running task 24.0 in stage 0.0 (TID 24)
19/12/02 17:50:06 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:402653184+16777216
19/12/02 17:50:15 INFO PythonRunner: Times: total = 8413, boot = -94, init = 105, finish = 8402
19/12/02 17:50:15 INFO Executor: Finished task 24.0 in stage 0.0 (TID 24). 1742 bytes result sent to driver
19/12/02 17:50:15 INFO CoarseGrainedExecutorBackend: Got assigned task 26
19/12/02 17:50:15 INFO Executor: Running task 26.0 in stage 0.0 (TID 26)
19/12/02 17:50:15 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:436207616+16777216
19/12/02 17:50:23 INFO PythonRunner: Times: total = 8391, boot = -73, init = 85, finish = 8379
19/12/02 17:50:23 INFO Executor: Finished task 26.0 in stage 0.0 (TID 26). 1785 bytes result sent to driver
19/12/02 17:50:23 INFO CoarseGrainedExecutorBackend: Got assigned task 28
19/12/02 17:50:23 INFO Executor: Running task 28.0 in stage 0.0 (TID 28)
19/12/02 17:50:23 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:469762048+16777216
19/12/02 17:50:31 INFO PythonRunner: Times: total = 8310, boot = -51, init = 61, finish = 8300
19/12/02 17:50:31 INFO Executor: Finished task 28.0 in stage 0.0 (TID 28). 1742 bytes result sent to driver
19/12/02 17:50:31 INFO CoarseGrainedExecutorBackend: Got assigned task 30
19/12/02 17:50:31 INFO Executor: Running task 30.0 in stage 0.0 (TID 30)
19/12/02 17:50:31 INFO HadoopRDD: Input split: hdfs://master:54310/input/data.txt:503316480+16777216
19/12/02 17:50:40 INFO PythonRunner: Times: total = 8364, boot = -53, init = 63, finish = 8354
19/12/02 17:50:40 INFO Executor: Finished task 30.0 in stage 0.0 (TID 30). 1742 bytes result sent to driver
19/12/02 17:50:42 INFO CoarseGrainedExecutorBackend: Got assigned task 32
19/12/02 17:50:42 INFO Executor: Running task 0.0 in stage 1.0 (TID 32)
19/12/02 17:50:42 INFO MapOutputTrackerWorker: Updating epoch to 1 and clearing cache
19/12/02 17:50:42 INFO TorrentBroadcast: Started reading broadcast variable 2
19/12/02 17:50:42 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 29.6 KB, free 413.5 MB)
19/12/02 17:50:42 INFO TorrentBroadcast: Reading broadcast variable 2 took 12 ms
19/12/02 17:50:42 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 77.3 KB, free 413.5 MB)
19/12/02 17:50:42 INFO MapOutputTrackerWorker: Don't have map outputs for shuffle 0, fetching them
19/12/02 17:50:42 INFO MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@master:39269)
19/12/02 17:50:42 INFO MapOutputTrackerWorker: Got the output locations
19/12/02 17:50:42 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/12/02 17:50:42 INFO TransportClientFactory: Successfully created connection to /172.23.0.3:44147 after 1 ms (0 ms spent in bootstraps)
19/12/02 17:50:42 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 28 ms
19/12/02 17:50:42 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/12/02 17:50:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/12/02 17:50:42 INFO PythonRunner: Times: total = 71, boot = -2421, init = 2491, finish = 1
19/12/02 17:50:43 INFO FileOutputCommitter: Saved output of task 'attempt_20191202094820_0008_m_000000_0' to hdfs://master:54310/output/_temporary/0/task_20191202094820_0008_m_000000
19/12/02 17:50:43 INFO SparkHadoopMapRedUtil: attempt_20191202094820_0008_m_000000_0: Committed
19/12/02 17:50:43 INFO Executor: Finished task 0.0 in stage 1.0 (TID 32). 2067 bytes result sent to driver
19/12/02 17:50:43 INFO CoarseGrainedExecutorBackend: Got assigned task 34
19/12/02 17:50:43 INFO Executor: Running task 2.0 in stage 1.0 (TID 34)
19/12/02 17:50:43 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/12/02 17:50:43 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 10 ms
19/12/02 17:50:43 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/12/02 17:50:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/12/02 17:50:43 INFO PythonRunner: Times: total = 69, boot = -264, init = 333, finish = 0
19/12/02 17:50:43 INFO FileOutputCommitter: Saved output of task 'attempt_20191202094820_0008_m_000002_0' to hdfs://master:54310/output/_temporary/0/task_20191202094820_0008_m_000002
19/12/02 17:50:43 INFO SparkHadoopMapRedUtil: attempt_20191202094820_0008_m_000002_0: Committed
19/12/02 17:50:43 INFO Executor: Finished task 2.0 in stage 1.0 (TID 34). 2024 bytes result sent to driver
19/12/02 17:50:43 INFO CoarseGrainedExecutorBackend: Got assigned task 36
19/12/02 17:50:43 INFO Executor: Running task 4.0 in stage 1.0 (TID 36)
19/12/02 17:50:43 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/12/02 17:50:43 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 16 ms
19/12/02 17:50:43 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/12/02 17:50:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/12/02 17:50:43 INFO PythonRunner: Times: total = 64, boot = -128, init = 192, finish = 0
19/12/02 17:50:43 INFO FileOutputCommitter: Saved output of task 'attempt_20191202094820_0008_m_000004_0' to hdfs://master:54310/output/_temporary/0/task_20191202094820_0008_m_000004
19/12/02 17:50:43 INFO SparkHadoopMapRedUtil: attempt_20191202094820_0008_m_000004_0: Committed
19/12/02 17:50:43 INFO Executor: Finished task 4.0 in stage 1.0 (TID 36). 2067 bytes result sent to driver
19/12/02 17:50:43 INFO CoarseGrainedExecutorBackend: Got assigned task 38
19/12/02 17:50:43 INFO Executor: Running task 6.0 in stage 1.0 (TID 38)
19/12/02 17:50:43 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/12/02 17:50:43 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 10 ms
19/12/02 17:50:43 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/12/02 17:50:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/12/02 17:50:43 INFO PythonRunner: Times: total = 71, boot = -139, init = 209, finish = 1
19/12/02 17:50:43 INFO FileOutputCommitter: Saved output of task 'attempt_20191202094820_0008_m_000006_0' to hdfs://master:54310/output/_temporary/0/task_20191202094820_0008_m_000006
19/12/02 17:50:43 INFO SparkHadoopMapRedUtil: attempt_20191202094820_0008_m_000006_0: Committed
19/12/02 17:50:43 INFO Executor: Finished task 6.0 in stage 1.0 (TID 38). 2024 bytes result sent to driver
19/12/02 17:50:43 INFO CoarseGrainedExecutorBackend: Got assigned task 40
19/12/02 17:50:43 INFO Executor: Running task 8.0 in stage 1.0 (TID 40)
19/12/02 17:50:43 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/12/02 17:50:43 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 11 ms
19/12/02 17:50:43 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/12/02 17:50:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/12/02 17:50:43 INFO PythonRunner: Times: total = 62, boot = -83, init = 145, finish = 0
19/12/02 17:50:43 INFO FileOutputCommitter: Saved output of task 'attempt_20191202094820_0008_m_000008_0' to hdfs://master:54310/output/_temporary/0/task_20191202094820_0008_m_000008
19/12/02 17:50:43 INFO SparkHadoopMapRedUtil: attempt_20191202094820_0008_m_000008_0: Committed
19/12/02 17:50:43 INFO Executor: Finished task 8.0 in stage 1.0 (TID 40). 2024 bytes result sent to driver
19/12/02 17:50:43 INFO CoarseGrainedExecutorBackend: Got assigned task 42
19/12/02 17:50:43 INFO Executor: Running task 10.0 in stage 1.0 (TID 42)
19/12/02 17:50:43 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/12/02 17:50:43 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 7 ms
19/12/02 17:50:43 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/12/02 17:50:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/12/02 17:50:44 INFO PythonRunner: Times: total = 66, boot = -127, init = 193, finish = 0
19/12/02 17:50:44 INFO FileOutputCommitter: Saved output of task 'attempt_20191202094820_0008_m_000010_0' to hdfs://master:54310/output/_temporary/0/task_20191202094820_0008_m_000010
19/12/02 17:50:44 INFO SparkHadoopMapRedUtil: attempt_20191202094820_0008_m_000010_0: Committed
19/12/02 17:50:44 INFO Executor: Finished task 10.0 in stage 1.0 (TID 42). 2024 bytes result sent to driver
19/12/02 17:50:44 INFO CoarseGrainedExecutorBackend: Got assigned task 44
19/12/02 17:50:44 INFO Executor: Running task 12.0 in stage 1.0 (TID 44)
19/12/02 17:50:44 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/12/02 17:50:44 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 5 ms
19/12/02 17:50:44 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/12/02 17:50:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/12/02 17:50:44 INFO PythonRunner: Times: total = 70, boot = -119, init = 189, finish = 0
19/12/02 17:50:44 INFO FileOutputCommitter: Saved output of task 'attempt_20191202094820_0008_m_000012_0' to hdfs://master:54310/output/_temporary/0/task_20191202094820_0008_m_000012
19/12/02 17:50:44 INFO SparkHadoopMapRedUtil: attempt_20191202094820_0008_m_000012_0: Committed
19/12/02 17:50:44 INFO Executor: Finished task 12.0 in stage 1.0 (TID 44). 2024 bytes result sent to driver
19/12/02 17:50:44 INFO CoarseGrainedExecutorBackend: Got assigned task 46
19/12/02 17:50:44 INFO Executor: Running task 14.0 in stage 1.0 (TID 46)
19/12/02 17:50:44 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/12/02 17:50:44 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 15 ms
19/12/02 17:50:44 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/12/02 17:50:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/12/02 17:50:44 INFO PythonRunner: Times: total = 70, boot = -135, init = 205, finish = 0
19/12/02 17:50:44 INFO FileOutputCommitter: Saved output of task 'attempt_20191202094820_0008_m_000014_0' to hdfs://master:54310/output/_temporary/0/task_20191202094820_0008_m_000014
19/12/02 17:50:44 INFO SparkHadoopMapRedUtil: attempt_20191202094820_0008_m_000014_0: Committed
19/12/02 17:50:44 INFO Executor: Finished task 14.0 in stage 1.0 (TID 46). 2024 bytes result sent to driver
19/12/02 17:50:44 INFO CoarseGrainedExecutorBackend: Got assigned task 48
19/12/02 17:50:44 INFO Executor: Running task 16.0 in stage 1.0 (TID 48)
19/12/02 17:50:44 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/12/02 17:50:44 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 17 ms
19/12/02 17:50:44 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/12/02 17:50:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/12/02 17:50:44 INFO PythonRunner: Times: total = 58, boot = -135, init = 192, finish = 1
19/12/02 17:50:44 INFO FileOutputCommitter: Saved output of task 'attempt_20191202094820_0008_m_000016_0' to hdfs://master:54310/output/_temporary/0/task_20191202094820_0008_m_000016
19/12/02 17:50:44 INFO SparkHadoopMapRedUtil: attempt_20191202094820_0008_m_000016_0: Committed
19/12/02 17:50:44 INFO Executor: Finished task 16.0 in stage 1.0 (TID 48). 2024 bytes result sent to driver
19/12/02 17:50:44 INFO CoarseGrainedExecutorBackend: Got assigned task 50
19/12/02 17:50:44 INFO Executor: Running task 18.0 in stage 1.0 (TID 50)
19/12/02 17:50:44 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/12/02 17:50:44 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 11 ms
19/12/02 17:50:44 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/12/02 17:50:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/12/02 17:50:44 INFO PythonRunner: Times: total = 61, boot = -71, init = 132, finish = 0
19/12/02 17:50:44 INFO FileOutputCommitter: Saved output of task 'attempt_20191202094820_0008_m_000018_0' to hdfs://master:54310/output/_temporary/0/task_20191202094820_0008_m_000018
19/12/02 17:50:44 INFO SparkHadoopMapRedUtil: attempt_20191202094820_0008_m_000018_0: Committed
19/12/02 17:50:44 INFO Executor: Finished task 18.0 in stage 1.0 (TID 50). 2024 bytes result sent to driver
19/12/02 17:50:44 INFO CoarseGrainedExecutorBackend: Got assigned task 52
19/12/02 17:50:44 INFO Executor: Running task 20.0 in stage 1.0 (TID 52)
19/12/02 17:50:44 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/12/02 17:50:44 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 15 ms
19/12/02 17:50:44 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/12/02 17:50:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/12/02 17:50:44 INFO PythonRunner: Times: total = 70, boot = -91, init = 161, finish = 0
19/12/02 17:50:45 INFO FileOutputCommitter: Saved output of task 'attempt_20191202094820_0008_m_000020_0' to hdfs://master:54310/output/_temporary/0/task_20191202094820_0008_m_000020
19/12/02 17:50:45 INFO SparkHadoopMapRedUtil: attempt_20191202094820_0008_m_000020_0: Committed
19/12/02 17:50:45 INFO Executor: Finished task 20.0 in stage 1.0 (TID 52). 2024 bytes result sent to driver
19/12/02 17:50:45 INFO CoarseGrainedExecutorBackend: Got assigned task 54
19/12/02 17:50:45 INFO Executor: Running task 22.0 in stage 1.0 (TID 54)
19/12/02 17:50:45 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/12/02 17:50:45 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 3 ms
19/12/02 17:50:45 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/12/02 17:50:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/12/02 17:50:45 INFO PythonRunner: Times: total = 75, boot = -94, init = 169, finish = 0
19/12/02 17:50:45 INFO FileOutputCommitter: Saved output of task 'attempt_20191202094820_0008_m_000022_0' to hdfs://master:54310/output/_temporary/0/task_20191202094820_0008_m_000022
19/12/02 17:50:45 INFO SparkHadoopMapRedUtil: attempt_20191202094820_0008_m_000022_0: Committed
19/12/02 17:50:45 INFO Executor: Finished task 22.0 in stage 1.0 (TID 54). 2067 bytes result sent to driver
19/12/02 17:50:45 INFO CoarseGrainedExecutorBackend: Got assigned task 56
19/12/02 17:50:45 INFO Executor: Running task 24.0 in stage 1.0 (TID 56)
19/12/02 17:50:45 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/12/02 17:50:45 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 3 ms
19/12/02 17:50:45 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/12/02 17:50:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/12/02 17:50:45 INFO PythonRunner: Times: total = 78, boot = -115, init = 193, finish = 0
19/12/02 17:50:45 INFO FileOutputCommitter: Saved output of task 'attempt_20191202094820_0008_m_000024_0' to hdfs://master:54310/output/_temporary/0/task_20191202094820_0008_m_000024
19/12/02 17:50:45 INFO SparkHadoopMapRedUtil: attempt_20191202094820_0008_m_000024_0: Committed
19/12/02 17:50:45 INFO Executor: Finished task 24.0 in stage 1.0 (TID 56). 2024 bytes result sent to driver
19/12/02 17:50:45 INFO CoarseGrainedExecutorBackend: Got assigned task 58
19/12/02 17:50:45 INFO Executor: Running task 26.0 in stage 1.0 (TID 58)
19/12/02 17:50:45 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/12/02 17:50:45 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 12 ms
19/12/02 17:50:45 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/12/02 17:50:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/12/02 17:50:45 INFO PythonRunner: Times: total = 69, boot = -103, init = 171, finish = 1
19/12/02 17:50:45 INFO FileOutputCommitter: Saved output of task 'attempt_20191202094820_0008_m_000026_0' to hdfs://master:54310/output/_temporary/0/task_20191202094820_0008_m_000026
19/12/02 17:50:45 INFO SparkHadoopMapRedUtil: attempt_20191202094820_0008_m_000026_0: Committed
19/12/02 17:50:45 INFO Executor: Finished task 26.0 in stage 1.0 (TID 58). 2024 bytes result sent to driver
19/12/02 17:50:45 INFO CoarseGrainedExecutorBackend: Got assigned task 60
19/12/02 17:50:45 INFO Executor: Running task 29.0 in stage 1.0 (TID 60)
19/12/02 17:50:45 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/12/02 17:50:45 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 5 ms
19/12/02 17:50:45 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/12/02 17:50:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/12/02 17:50:45 INFO PythonRunner: Times: total = 66, boot = -102, init = 168, finish = 0
19/12/02 17:50:45 INFO FileOutputCommitter: Saved output of task 'attempt_20191202094820_0008_m_000029_0' to hdfs://master:54310/output/_temporary/0/task_20191202094820_0008_m_000029
19/12/02 17:50:45 INFO SparkHadoopMapRedUtil: attempt_20191202094820_0008_m_000029_0: Committed
19/12/02 17:50:45 INFO Executor: Finished task 29.0 in stage 1.0 (TID 60). 2024 bytes result sent to driver
19/12/02 17:50:45 INFO CoarseGrainedExecutorBackend: Got assigned task 62
19/12/02 17:50:45 INFO Executor: Running task 31.0 in stage 1.0 (TID 62)
19/12/02 17:50:45 INFO ShuffleBlockFetcherIterator: Getting 32 non-empty blocks including 16 local blocks and 16 remote blocks
19/12/02 17:50:45 INFO ShuffleBlockFetcherIterator: Started 1 remote fetches in 1 ms
19/12/02 17:50:45 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/12/02 17:50:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/12/02 17:50:45 INFO PythonRunner: Times: total = 82, boot = -89, init = 171, finish = 0
19/12/02 17:50:45 INFO FileOutputCommitter: Saved output of task 'attempt_20191202094820_0008_m_000031_0' to hdfs://master:54310/output/_temporary/0/task_20191202094820_0008_m_000031
19/12/02 17:50:45 INFO SparkHadoopMapRedUtil: attempt_20191202094820_0008_m_000031_0: Committed
19/12/02 17:50:45 INFO Executor: Finished task 31.0 in stage 1.0 (TID 62). 2024 bytes result sent to driver
19/12/02 17:50:46 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
19/12/02 17:50:46 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
tdown
